{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ffbdc41",
   "metadata": {},
   "source": [
    "# Melbourne Airbnb Price Classification\n",
    "\n",
    "This notebook performs comprehensive data preprocessing and feature engineering on the Melbourne Airbnb dataset, followed by multi-class price prediction using multiple machine learning models.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Data Loading & Initial Exploration](#data-loading)\n",
    "2. [Feature Engineering Pipeline](#feature-engineering)\n",
    "   - Column Removal\n",
    "   - Text Vectorization\n",
    "   - Datetime Processing\n",
    "   - Boolean/Binary Conversion\n",
    "   - Categorical Encoding\n",
    "   - List-Type Columns\n",
    "   - Numeric Conversion\n",
    "3. [Missing Value Handling](#missing-values)\n",
    "4. [Model Training & Evaluation](#modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f34cb0f",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Initial Exploration {#data-loading}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "623dd3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (18316, 103)\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_url</th>\n",
       "      <th>scrape_id</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>name</th>\n",
       "      <th>summary</th>\n",
       "      <th>space</th>\n",
       "      <th>description</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>notes</th>\n",
       "      <th>transit</th>\n",
       "      <th>...</th>\n",
       "      <th>host_verifications_manual_offline</th>\n",
       "      <th>host_verifications_offline_government_id</th>\n",
       "      <th>host_verifications_selfie</th>\n",
       "      <th>host_verifications_reviews</th>\n",
       "      <th>host_verifications_identity_manual</th>\n",
       "      <th>host_verifications_sesame_offline</th>\n",
       "      <th>host_verifications_weibo</th>\n",
       "      <th>host_verifications_email</th>\n",
       "      <th>host_verifications_sent_id</th>\n",
       "      <th>host_verifications_phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"https://www.airbnb.com/rooms/25586695\"</td>\n",
       "      <td>2.018120e+13</td>\n",
       "      <td>\"12/7/2018\"</td>\n",
       "      <td>\"Beach side, art deco flat in heart of St Kilda\"</td>\n",
       "      <td>\"A beautiful art deco flat right in the heart ...</td>\n",
       "      <td>\"5 minutes walk to the beach.  1 minute walk t...</td>\n",
       "      <td>\"A beautiful art deco flat right in the heart ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"https://www.airbnb.com/rooms/1057401\"</td>\n",
       "      <td>2.018120e+13</td>\n",
       "      <td>\"12/7/2018\"</td>\n",
       "      <td>\"Modern Bayside Studio Apartment\"</td>\n",
       "      <td>\"Self contained modern apartment with its own ...</td>\n",
       "      <td>\"We offer a self-contained modern apartment wi...</td>\n",
       "      <td>\"Self contained modern apartment with its own ...</td>\n",
       "      <td>\"The apartment is in a quiet residential neigh...</td>\n",
       "      <td>None</td>\n",
       "      <td>\"There is street parking available outside at ...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"https://www.airbnb.com/rooms/24949385\"</td>\n",
       "      <td>2.018120e+13</td>\n",
       "      <td>\"12/7/2018\"</td>\n",
       "      <td>\"Spacious Saint kilda home with a View\"</td>\n",
       "      <td>\"Short term Flatshare in the heart of St Kilda...</td>\n",
       "      <td>None</td>\n",
       "      <td>\"Short term Flatshare in the heart of St Kilda...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"https://www.airbnb.com/rooms/20075093\"</td>\n",
       "      <td>2.018120e+13</td>\n",
       "      <td>\"12/7/2018\"</td>\n",
       "      <td>\"Rewarding Richmond Location-Outstanding Apart...</td>\n",
       "      <td>\"Welcome to my amazing apartment located in th...</td>\n",
       "      <td>\"It will be a pleasure to host you in my fanta...</td>\n",
       "      <td>\"Welcome to my amazing apartment located in th...</td>\n",
       "      <td>\"Richmond is one of the most vibrant and diver...</td>\n",
       "      <td>\"Please remove your shoes whilst inside, as th...</td>\n",
       "      <td>\"To go directly into the CBD just walk 200 met...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"https://www.airbnb.com/rooms/16275657\"</td>\n",
       "      <td>2.018120e+13</td>\n",
       "      <td>\"12/7/2018\"</td>\n",
       "      <td>\"Close to the centre of Melbourne.\"</td>\n",
       "      <td>\"Beautiful 3 bedroomed double story townhouse ...</td>\n",
       "      <td>\"Two living areas - use of both. 2 bedrooms.  ...</td>\n",
       "      <td>\"Beautiful 3 bedroomed double story townhouse ...</td>\n",
       "      <td>\"Double story townhouse. Host has own space up...</td>\n",
       "      <td>None</td>\n",
       "      <td>\"Easy public transport system, close by. - tra...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               listing_url     scrape_id last_scraped  \\\n",
       "0  \"https://www.airbnb.com/rooms/25586695\"  2.018120e+13  \"12/7/2018\"   \n",
       "1   \"https://www.airbnb.com/rooms/1057401\"  2.018120e+13  \"12/7/2018\"   \n",
       "2  \"https://www.airbnb.com/rooms/24949385\"  2.018120e+13  \"12/7/2018\"   \n",
       "3  \"https://www.airbnb.com/rooms/20075093\"  2.018120e+13  \"12/7/2018\"   \n",
       "4  \"https://www.airbnb.com/rooms/16275657\"  2.018120e+13  \"12/7/2018\"   \n",
       "\n",
       "                                                name  \\\n",
       "0   \"Beach side, art deco flat in heart of St Kilda\"   \n",
       "1                  \"Modern Bayside Studio Apartment\"   \n",
       "2            \"Spacious Saint kilda home with a View\"   \n",
       "3  \"Rewarding Richmond Location-Outstanding Apart...   \n",
       "4                \"Close to the centre of Melbourne.\"   \n",
       "\n",
       "                                             summary  \\\n",
       "0  \"A beautiful art deco flat right in the heart ...   \n",
       "1  \"Self contained modern apartment with its own ...   \n",
       "2  \"Short term Flatshare in the heart of St Kilda...   \n",
       "3  \"Welcome to my amazing apartment located in th...   \n",
       "4  \"Beautiful 3 bedroomed double story townhouse ...   \n",
       "\n",
       "                                               space  \\\n",
       "0  \"5 minutes walk to the beach.  1 minute walk t...   \n",
       "1  \"We offer a self-contained modern apartment wi...   \n",
       "2                                               None   \n",
       "3  \"It will be a pleasure to host you in my fanta...   \n",
       "4  \"Two living areas - use of both. 2 bedrooms.  ...   \n",
       "\n",
       "                                         description  \\\n",
       "0  \"A beautiful art deco flat right in the heart ...   \n",
       "1  \"Self contained modern apartment with its own ...   \n",
       "2  \"Short term Flatshare in the heart of St Kilda...   \n",
       "3  \"Welcome to my amazing apartment located in th...   \n",
       "4  \"Beautiful 3 bedroomed double story townhouse ...   \n",
       "\n",
       "                               neighborhood_overview  \\\n",
       "0                                               None   \n",
       "1  \"The apartment is in a quiet residential neigh...   \n",
       "2                                               None   \n",
       "3  \"Richmond is one of the most vibrant and diver...   \n",
       "4  \"Double story townhouse. Host has own space up...   \n",
       "\n",
       "                                               notes  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3  \"Please remove your shoes whilst inside, as th...   \n",
       "4                                               None   \n",
       "\n",
       "                                             transit  ...  \\\n",
       "0                                               None  ...   \n",
       "1  \"There is street parking available outside at ...  ...   \n",
       "2                                               None  ...   \n",
       "3  \"To go directly into the CBD just walk 200 met...  ...   \n",
       "4  \"Easy public transport system, close by. - tra...  ...   \n",
       "\n",
       "  host_verifications_manual_offline host_verifications_offline_government_id  \\\n",
       "0                             False                                    False   \n",
       "1                             False                                     True   \n",
       "2                             False                                    False   \n",
       "3                             False                                     True   \n",
       "4                             False                                    False   \n",
       "\n",
       "  host_verifications_selfie host_verifications_reviews  \\\n",
       "0                     False                       True   \n",
       "1                      True                       True   \n",
       "2                     False                       True   \n",
       "3                     False                       True   \n",
       "4                     False                       True   \n",
       "\n",
       "   host_verifications_identity_manual host_verifications_sesame_offline  \\\n",
       "0                               False                             False   \n",
       "1                                True                             False   \n",
       "2                               False                             False   \n",
       "3                               False                             False   \n",
       "4                               False                             False   \n",
       "\n",
       "  host_verifications_weibo host_verifications_email  \\\n",
       "0                    False                     True   \n",
       "1                    False                     True   \n",
       "2                    False                     True   \n",
       "3                    False                     True   \n",
       "4                    False                    False   \n",
       "\n",
       "  host_verifications_sent_id host_verifications_phone  \n",
       "0                      False                     True  \n",
       "1                      False                     True  \n",
       "2                      False                     True  \n",
       "3                      False                    False  \n",
       "4                      False                     True  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arff\n",
    "import re\n",
    "import ast\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from xgboost import XGBClassifier\n",
    "from category_encoders import TargetEncoder\n",
    "import joblib\n",
    "\n",
    "# Load the ARFF data file\n",
    "with open('data/Melbourne_Airbnb', 'r') as f:\n",
    "    data = arff.load(f)\n",
    "\n",
    "df = pd.DataFrame(data['data'], columns=[a[0] for a in data['attributes']])\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30723b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values (sorted by percentage):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>license</th>\n",
       "      <td>18297</td>\n",
       "      <td>99.896266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_price</th>\n",
       "      <td>16810</td>\n",
       "      <td>91.777681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekly_price</th>\n",
       "      <td>16307</td>\n",
       "      <td>89.031448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notes</th>\n",
       "      <td>9037</td>\n",
       "      <td>49.339375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_about</th>\n",
       "      <td>7309</td>\n",
       "      <td>39.905001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <td>6791</td>\n",
       "      <td>37.076873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interaction</th>\n",
       "      <td>6665</td>\n",
       "      <td>36.388950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transit</th>\n",
       "      <td>6372</td>\n",
       "      <td>34.789255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_neighborhood</th>\n",
       "      <td>6369</td>\n",
       "      <td>34.772876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house_rules</th>\n",
       "      <td>6276</td>\n",
       "      <td>34.265123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>access</th>\n",
       "      <td>6191</td>\n",
       "      <td>33.801048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security_deposit</th>\n",
       "      <td>5962</td>\n",
       "      <td>32.550775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_rate</th>\n",
       "      <td>5807</td>\n",
       "      <td>31.704521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time</th>\n",
       "      <td>5807</td>\n",
       "      <td>31.704521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>space</th>\n",
       "      <td>4857</td>\n",
       "      <td>26.517799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighborhood</th>\n",
       "      <td>4631</td>\n",
       "      <td>25.283905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_value</th>\n",
       "      <td>4599</td>\n",
       "      <td>25.109194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <td>4599</td>\n",
       "      <td>25.109194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_location</th>\n",
       "      <td>4598</td>\n",
       "      <td>25.103734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_accuracy</th>\n",
       "      <td>4587</td>\n",
       "      <td>25.043678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_communication</th>\n",
       "      <td>4587</td>\n",
       "      <td>25.043678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <td>4582</td>\n",
       "      <td>25.016379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_rating</th>\n",
       "      <td>4576</td>\n",
       "      <td>24.983621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleaning_fee</th>\n",
       "      <td>4509</td>\n",
       "      <td>24.617820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews_per_month</th>\n",
       "      <td>4202</td>\n",
       "      <td>22.941690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_review</th>\n",
       "      <td>4202</td>\n",
       "      <td>22.941690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_review</th>\n",
       "      <td>4202</td>\n",
       "      <td>22.941690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>559</td>\n",
       "      <td>3.051976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>263</td>\n",
       "      <td>1.435903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode</th>\n",
       "      <td>114</td>\n",
       "      <td>0.622407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>48</td>\n",
       "      <td>0.262066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>28</td>\n",
       "      <td>0.152872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_location</th>\n",
       "      <td>22</td>\n",
       "      <td>0.120114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suburb</th>\n",
       "      <td>17</td>\n",
       "      <td>0.092815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>11</td>\n",
       "      <td>0.060057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>5</td>\n",
       "      <td>0.027299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>3</td>\n",
       "      <td>0.016379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_since</th>\n",
       "      <td>3</td>\n",
       "      <td>0.016379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_name</th>\n",
       "      <td>3</td>\n",
       "      <td>0.016379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_identity_verified</th>\n",
       "      <td>3</td>\n",
       "      <td>0.016379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_thumbnail_url</th>\n",
       "      <td>3</td>\n",
       "      <td>0.016379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <td>3</td>\n",
       "      <td>0.016379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_picture_url</th>\n",
       "      <td>3</td>\n",
       "      <td>0.016379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>2</td>\n",
       "      <td>0.010919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Missing Values  % of Total\n",
       "license                               18297   99.896266\n",
       "monthly_price                         16810   91.777681\n",
       "weekly_price                          16307   89.031448\n",
       "notes                                  9037   49.339375\n",
       "host_about                             7309   39.905001\n",
       "neighborhood_overview                  6791   37.076873\n",
       "interaction                            6665   36.388950\n",
       "transit                                6372   34.789255\n",
       "host_neighborhood                      6369   34.772876\n",
       "house_rules                            6276   34.265123\n",
       "access                                 6191   33.801048\n",
       "security_deposit                       5962   32.550775\n",
       "host_response_rate                     5807   31.704521\n",
       "host_response_time                     5807   31.704521\n",
       "space                                  4857   26.517799\n",
       "neighborhood                           4631   25.283905\n",
       "review_scores_value                    4599   25.109194\n",
       "review_scores_checkin                  4599   25.109194\n",
       "review_scores_location                 4598   25.103734\n",
       "review_scores_accuracy                 4587   25.043678\n",
       "review_scores_communication            4587   25.043678\n",
       "review_scores_cleanliness              4582   25.016379\n",
       "review_scores_rating                   4576   24.983621\n",
       "cleaning_fee                           4509   24.617820\n",
       "reviews_per_month                      4202   22.941690\n",
       "first_review                           4202   22.941690\n",
       "last_review                            4202   22.941690\n",
       "summary                                 559    3.051976\n",
       "description                             263    1.435903\n",
       "zipcode                                 114    0.622407\n",
       "state                                    48    0.262066\n",
       "beds                                     28    0.152872\n",
       "host_location                            22    0.120114\n",
       "suburb                                   17    0.092815\n",
       "bathrooms                                11    0.060057\n",
       "bedrooms                                  5    0.027299\n",
       "host_is_superhost                         3    0.016379\n",
       "host_since                                3    0.016379\n",
       "host_name                                 3    0.016379\n",
       "host_identity_verified                    3    0.016379\n",
       "host_thumbnail_url                        3    0.016379\n",
       "host_has_profile_pic                      3    0.016379\n",
       "host_picture_url                          3    0.016379\n",
       "name                                      2    0.010919"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing = df.isna().sum()\n",
    "percent = (missing / len(df)) * 100\n",
    "missing_table = pd.DataFrame({'Missing Values': missing, '% of Total': percent})\n",
    "\n",
    "print(\"Columns with missing values (sorted by percentage):\")\n",
    "missing_table[missing_table['Missing Values'] > 0].sort_values('% of Total', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136f23b8",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering Pipeline {#feature-engineering}\n",
    "\n",
    "### 2.1 Initial Column Removal\n",
    "\n",
    "Remove columns that are:\n",
    "- Unnecessary identifiers (URLs, IDs)\n",
    "- Have >90% missing values\n",
    "- Single-value columns\n",
    "- Data leakage risks (price, dates)\n",
    "- Redundant location fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b79b51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after column removal: (18316, 81)\n"
     ]
    }
   ],
   "source": [
    "# Remove unnecessary columns\n",
    "cols_to_remove = [\n",
    "    # URLs and IDs\n",
    "    'listing_url', 'scrape_id', 'last_scraped', 'picture_url', 'host_id', \n",
    "    'host_url', 'host_thumbnail_url', 'host_picture_url', 'license',\n",
    "    # High missing rate\n",
    "    'monthly_price', 'weekly_price',\n",
    "    # Redundant or single-value\n",
    "    'country_code', 'country', 'requires_license', 'calendar_last_scraped',\n",
    "    # Redundant location fields\n",
    "    'street', 'neighborhood', 'smart_location', 'host_name', 'suburb', 'city',\n",
    "    # Potential data leakage\n",
    "    'price'\n",
    "]\n",
    "\n",
    "df_clean = df.drop(columns=cols_to_remove)\n",
    "print(f\"Shape after column removal: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31723d29",
   "metadata": {},
   "source": [
    "### 2.2 Text Vectorization\n",
    "\n",
    "Combine all text columns and convert to embeddings using sentence-transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad70b410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text columns combined. New shape: (18316, 71)\n"
     ]
    }
   ],
   "source": [
    "# Define text columns to vectorize\n",
    "text_columns = [\n",
    "    'name', 'summary', 'space', 'description', 'neighborhood_overview',\n",
    "    'notes', 'transit', 'access', 'interaction', 'house_rules', 'host_about'\n",
    "]\n",
    "\n",
    "# Fill missing values with empty strings\n",
    "df_clean[text_columns] = df_clean[text_columns].fillna('')\n",
    "\n",
    "# Combine all text into one column\n",
    "df_clean['combined_text'] = df_clean[text_columns].agg(' '.join, axis=1)\n",
    "\n",
    "# Drop individual text columns\n",
    "df_clean = df_clean.drop(columns=text_columns)\n",
    "\n",
    "print(f\"Text columns combined. New shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35be1cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Batches: 100%|██████████| 287/287 [16:55<00:00,  3.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text embeddings generated (384 dimensions per listing)\n",
      "Embedding sample shape: (384,)\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings using sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(df_clean['combined_text'].tolist(), batch_size=64, show_progress_bar=True)\n",
    "\n",
    "# Store embeddings as numpy arrays\n",
    "df_clean['text_numeric'] = list(embeddings)\n",
    "df_clean = df_clean.drop(columns=['combined_text'])\n",
    "\n",
    "print(f\"Text embeddings generated (384 dimensions per listing)\")\n",
    "print(f\"Embedding sample shape: {df_clean['text_numeric'].iloc[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d04d38b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_pickle('data/df_encoded.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dbf01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.read_pickle('data/df_encoded.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3ee0b3",
   "metadata": {},
   "source": [
    "### 2.3 Datetime Processing\n",
    "\n",
    "Convert date strings to numeric features:\n",
    "- `host_since` → `host_experience_days`\n",
    "- `first_review`, `last_review` → `review_recent_days`\n",
    "- `calendar_updated` → `calendar_updated_days_ago`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93599491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date features engineered\n"
     ]
    }
   ],
   "source": [
    "# Process date columns\n",
    "date_cols = [\"host_since\", \"first_review\", \"last_review\"]\n",
    "\n",
    "for col in date_cols:\n",
    "    df_clean[col] = (\n",
    "        df_clean[col]\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.strip('\"')\n",
    "        .replace({\"nan\": np.nan})\n",
    "    )\n",
    "    df_clean[col] = pd.to_datetime(df_clean[col], format=\"%m/%d/%Y\", errors=\"coerce\")\n",
    "\n",
    "# Create derived features\n",
    "today = pd.Timestamp.today()\n",
    "df_clean[\"host_experience_days\"] = (today - df_clean[\"host_since\"]).dt.days\n",
    "df_clean['review_recent_days'] = (df_clean['last_review'] - df_clean['first_review']).dt.days\n",
    "\n",
    "# Drop original date columns\n",
    "df_clean.drop(columns=[\"host_since\", \"first_review\", \"last_review\"], inplace=True)\n",
    "\n",
    "print(\"Date features engineered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d211d63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calendar updated converted to days\n"
     ]
    }
   ],
   "source": [
    "# Convert calendar_updated to numeric days\n",
    "def calendar_updated_to_days(val):\n",
    "    \"\"\"Convert calendar_updated text to numeric days ago.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    s = str(val).strip().strip('\"').strip().lower()\n",
    "    if s in (\"\", \"none\", \"never\"):\n",
    "        return np.nan\n",
    "    if s == \"today\":\n",
    "        return 0\n",
    "    if s == \"yesterday\":\n",
    "        return 1\n",
    "    \n",
    "    # Extract number\n",
    "    if s.startswith((\"a \", \"an \")):\n",
    "        n = 1\n",
    "    else:\n",
    "        m = re.search(r\"(\\d+)\", s)\n",
    "        n = int(m.group(1)) if m else None\n",
    "    \n",
    "    if n is None:\n",
    "        return np.nan\n",
    "    \n",
    "    # Convert to days\n",
    "    if \"day\" in s:\n",
    "        return n\n",
    "    if \"week\" in s:\n",
    "        return n * 7\n",
    "    if \"month\" in s:\n",
    "        return n * 30\n",
    "    if \"year\" in s:\n",
    "        return n * 365\n",
    "    return np.nan\n",
    "\n",
    "df_clean[\"calendar_updated_days_ago\"] = df_clean[\"calendar_updated\"].apply(calendar_updated_to_days).astype(float)\n",
    "df_clean.drop(columns=[\"calendar_updated\"], inplace=True)\n",
    "\n",
    "print(\"Calendar updated converted to days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e26e487",
   "metadata": {},
   "source": [
    "### 2.4 Boolean/Binary Conversion\n",
    "\n",
    "Convert boolean-like strings ('t'/'f', 'True'/'False') to binary (0/1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27bb116f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22009/2617151066.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\n",
      "/tmp/ipykernel_22009/2617151066.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\n",
      "/tmp/ipykernel_22009/2617151066.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\n",
      "/tmp/ipykernel_22009/2617151066.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\n",
      "/tmp/ipykernel_22009/2617151066.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\n",
      "/tmp/ipykernel_22009/2617151066.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\n",
      "/tmp/ipykernel_22009/2617151066.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\n",
      "/tmp/ipykernel_22009/2617151066.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\n",
      "/tmp/ipykernel_22009/2617151066.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\n",
      "/tmp/ipykernel_22009/2617151066.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\n",
      "/tmp/ipykernel_22009/2617151066.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\n",
      "/tmp/ipykernel_22009/2617151066.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\n",
      "/tmp/ipykernel_22009/2617151066.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\n",
      "/tmp/ipykernel_22009/2617151066.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\n",
      "/tmp/ipykernel_22009/2617151066.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\n",
      "/tmp/ipykernel_22009/2617151066.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\n",
      "/tmp/ipykernel_22009/2617151066.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\n",
      "/tmp/ipykernel_22009/2617151066.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\n",
      "/tmp/ipykernel_22009/2617151066.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\n",
      "/tmp/ipykernel_22009/2617151066.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 boolean columns converted to binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22009/2617151066.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\n",
      "/tmp/ipykernel_22009/2617151066.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\n",
      "/tmp/ipykernel_22009/2617151066.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\n",
      "/tmp/ipykernel_22009/2617151066.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\n"
     ]
    }
   ],
   "source": [
    "# Define all boolean columns\n",
    "bool_cols = [\n",
    "    'host_is_superhost', 'host_has_profile_pic', 'host_identity_verified',\n",
    "    'is_location_exact', 'has_availability', 'instant_bookable',\n",
    "    'host_verifications_jumio', 'host_verifications_government_id',\n",
    "    'host_verifications_kba', 'host_verifications_zhima_selfie',\n",
    "    'host_verifications_facebook', 'host_verifications_work_email',\n",
    "    'host_verifications_google', 'host_verifications_sesame',\n",
    "    'host_verifications_manual_online', 'host_verifications_manual_offline',\n",
    "    'host_verifications_offline_government_id', 'host_verifications_selfie',\n",
    "    'host_verifications_reviews', 'host_verifications_identity_manual',\n",
    "    'host_verifications_sesame_offline', 'host_verifications_weibo',\n",
    "    'host_verifications_email', 'host_verifications_sent_id',\n",
    "    'host_verifications_phone', 'require_guest_profile_picture', \n",
    "    'require_guest_phone_verification'\n",
    "]\n",
    "\n",
    "# Convert to binary\n",
    "for col in bool_cols:\n",
    "    df_clean[col] = (\n",
    "        df_clean[col]\n",
    "        .astype(str)\n",
    "        .str.strip(' \"\\'')\n",
    "        .replace({\n",
    "            't': 1, 'f': 0,\n",
    "            'True': 1, 'False': 0,\n",
    "            'true': 1, 'false': 0,\n",
    "            'nan': pd.NA, 'None': pd.NA, '': pd.NA\n",
    "        })\n",
    "        .astype('Int8')\n",
    "    )\n",
    "\n",
    "print(f\"{len(bool_cols)} boolean columns converted to binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4943d6f",
   "metadata": {},
   "source": [
    "### 2.5 Categorical Encoding\n",
    "\n",
    "Handle categorical variables with different strategies:\n",
    "- **One-hot encoding**: Low-cardinality categories\n",
    "- **Frequency encoding**: High-cardinality `property_type`\n",
    "- **State normalization**: Consolidate state variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72a9dc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in categorical columns filled with 'Unknown'\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values in categorical columns\n",
    "cat_cols = ['host_response_time', 'property_type', 'room_type', 'bed_type', \n",
    "            'cancellation_policy', 'state']\n",
    "df_clean[cat_cols] = df_clean[cat_cols].fillna('Unknown')\n",
    "\n",
    "print(\"Missing values in categorical columns filled with 'Unknown'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00b7f8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State values normalized: ['VIC' 'Unknown' 'NSW' 'QLD']\n"
     ]
    }
   ],
   "source": [
    "# Normalize state column (consolidate variations)\n",
    "def normalize_state(x):\n",
    "    \"\"\"Normalize state values to VIC/NSW/QLD/Unknown.\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return 'Unknown'\n",
    "    x_str = str(x).lower()\n",
    "    \n",
    "    vic_variations = [\n",
    "        'vic', 'victoria', '维多利亚', 'melbourne', '维多利亚州',\n",
    "        'south yarra vic 3141', 'somerton vic 3062', 'melbourne vic 3000',\n",
    "        'victory', 'vi', 'vic 3008', 'mel', 'wheelers hill vic 3150',\n",
    "        '維多利亞 vic', 'melbourne, victoria', 'doncaster vic 3108',\n",
    "        'wantirna south vic 3152', 'melbourne vic 3004', 'brunswick vic 3056'\n",
    "    ]\n",
    "    \n",
    "    if any(v.lower() in x_str for v in vic_variations):\n",
    "        return 'VIC'\n",
    "    elif 'nsw' in x_str:\n",
    "        return 'NSW'\n",
    "    elif 'qld' in x_str:\n",
    "        return 'QLD'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "df_clean['state'] = df_clean['state'].apply(normalize_state)\n",
    "print(f\"State values normalized: {df_clean['state'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79a640da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical encoding complete. Shape: (18316, 83)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode low-cardinality columns\n",
    "one_hot_cols = ['room_type', 'bed_type', 'cancellation_policy', 'state', 'host_response_time']\n",
    "df_clean = pd.get_dummies(df_clean, columns=one_hot_cols, drop_first=True)\n",
    "\n",
    "# Frequency encoding for high-cardinality property_type\n",
    "freq_encoding = df_clean['property_type'].value_counts(normalize=True).to_dict()\n",
    "df_clean['property_type_freq'] = df_clean['property_type'].map(freq_encoding)\n",
    "df_clean = df_clean.drop(columns=['property_type'])\n",
    "\n",
    "print(f\"Categorical encoding complete. Shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c21768",
   "metadata": {},
   "source": [
    "### 2.6 List-Type Columns (Multi-Label Binarization)\n",
    "\n",
    "Parse string-formatted lists (`amenities`, `host_verifications`) and create binary columns for each unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e2245e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amenities parsed\n"
     ]
    }
   ],
   "source": [
    "# Helper function to clean amenities\n",
    "def clean_token(tok):\n",
    "    \"\"\"Clean individual token by removing surrounding brackets/quotes.\"\"\"\n",
    "    if tok is None:\n",
    "        return None\n",
    "    s = str(tok).strip()\n",
    "    s = re.sub(r'^[\\{\\[\\(\"\\']+', '', s)\n",
    "    s = re.sub(r'[\\}\\]\\)\"\\']+$', '', s)\n",
    "    return s.strip()\n",
    "\n",
    "def clean_amenities_list(lst):\n",
    "    \"\"\"Parse and clean amenities list.\"\"\"\n",
    "    if pd.isna(lst):\n",
    "        return []\n",
    "    \n",
    "    if isinstance(lst, str):\n",
    "        try:\n",
    "            val = ast.literal_eval(lst)\n",
    "            if isinstance(val, (list, tuple)):\n",
    "                lst = list(val)\n",
    "        except Exception:\n",
    "            lst = [s for s in re.split(r',\\s*(?![^()]*\\))', lst) if s.strip()]\n",
    "    \n",
    "    if not isinstance(lst, (list, tuple)):\n",
    "        lst = [lst]\n",
    "    \n",
    "    # Clean and deduplicate\n",
    "    cleaned = []\n",
    "    seen = set()\n",
    "    for tok in lst:\n",
    "        tok_clean = clean_token(tok)\n",
    "        if tok_clean and len(tok_clean) > 1 and tok_clean not in seen:\n",
    "            cleaned.append(tok_clean)\n",
    "            seen.add(tok_clean)\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "def split_inner_commas(lst):\n",
    "    \"\"\"Split items that contain commas.\"\"\"\n",
    "    if not isinstance(lst, list):\n",
    "        return []\n",
    "    \n",
    "    new_list = []\n",
    "    for item in lst:\n",
    "        parts = [i.strip() for i in str(item).split(',') if i.strip()]\n",
    "        new_list.extend(parts)\n",
    "    \n",
    "    # Deduplicate\n",
    "    seen = set()\n",
    "    dedup = []\n",
    "    for t in new_list:\n",
    "        if t not in seen:\n",
    "            dedup.append(t)\n",
    "            seen.add(t)\n",
    "    return dedup\n",
    "\n",
    "# Apply cleaning to amenities\n",
    "df_clean['amenities_parsed'] = df_clean['amenities'].apply(clean_amenities_list).apply(split_inner_commas)\n",
    "\n",
    "print(\"Amenities parsed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55a5580b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Host verifications parsed\n"
     ]
    }
   ],
   "source": [
    "# Parse host_verifications\n",
    "def parse_host_verifications(x):\n",
    "    \"\"\"Parse host verifications string to list.\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    s = str(x).strip()\n",
    "    \n",
    "    if s.startswith('\"') and s.endswith('\"'):\n",
    "        s = s[1:-1].strip()\n",
    "    \n",
    "    try:\n",
    "        val = ast.literal_eval(s)\n",
    "        if isinstance(val, (list, tuple)):\n",
    "            return [str(tok).strip() for tok in val if str(tok).strip()]\n",
    "    except Exception:\n",
    "        s = re.sub(r'[\\[\\]\\{\\}\\'\"]', '', s)\n",
    "        parts = [p.strip() for p in s.split(',') if p.strip()]\n",
    "        return parts\n",
    "    \n",
    "    return []\n",
    "\n",
    "df_clean['verifications_parsed'] = df_clean['host_verifications'].apply(parse_host_verifications)\n",
    "\n",
    "print(\"Host verifications parsed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ef655fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-label binarization complete\n",
      "   - 186 amenity columns created\n",
      "   - 19 verification columns created\n",
      "   - Total shape: (18316, 286)\n"
     ]
    }
   ],
   "source": [
    "# Multi-label binarization\n",
    "mlb_amen = MultiLabelBinarizer(sparse_output=False)\n",
    "amenities_encoded = pd.DataFrame(\n",
    "    mlb_amen.fit_transform(df_clean['amenities_parsed']),\n",
    "    columns=[f\"amenity_{a}\" for a in mlb_amen.classes_],\n",
    "    index=df_clean.index\n",
    ")\n",
    "\n",
    "mlb_ver = MultiLabelBinarizer(sparse_output=False)\n",
    "verifications_encoded = pd.DataFrame(\n",
    "    mlb_ver.fit_transform(df_clean['verifications_parsed']),\n",
    "    columns=[f\"verify_{v}\" for v in mlb_ver.classes_],\n",
    "    index=df_clean.index\n",
    ")\n",
    "\n",
    "# Combine with main dataframe\n",
    "df_encoded = pd.concat([df_clean, amenities_encoded, verifications_encoded], axis=1)\n",
    "\n",
    "# Drop original and temporary columns\n",
    "df_encoded = df_encoded.drop(columns=['amenities', 'host_verifications', \n",
    "                                       'amenities_parsed', 'verifications_parsed'])\n",
    "\n",
    "print(f\"Multi-label binarization complete\")\n",
    "print(f\"   - {amenities_encoded.shape[1]} amenity columns created\")\n",
    "print(f\"   - {verifications_encoded.shape[1]} verification columns created\")\n",
    "print(f\"   - Total shape: {df_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b30cbd",
   "metadata": {},
   "source": [
    "### 2.7 Numeric Conversion\n",
    "\n",
    "Convert string-formatted numeric columns to proper numeric types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b67b339b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host_response_rate converted to float\n",
      "zipcode converted to numeric\n",
      "\n",
      "Final shape after all feature engineering: (18316, 284)\n"
     ]
    }
   ],
   "source": [
    "# Convert host_response_rate (percentage string to float)\n",
    "if 'host_response_rate' in df_encoded.columns:\n",
    "    df_encoded['host_response_rate'] = (\n",
    "        df_encoded['host_response_rate']\n",
    "        .astype(str)\n",
    "        .str.strip(\" '\\\"\") \n",
    "        .str.replace('%', '', regex=False)\n",
    "        .replace(['nan', 'None'], np.nan)\n",
    "        .astype(float)\n",
    "    )\n",
    "    print(\"host_response_rate converted to float\")\n",
    "\n",
    "# Convert zipcode (extract numeric part)\n",
    "if 'zipcode' in df_encoded.columns:\n",
    "    df_encoded['zipcode'] = (\n",
    "        df_encoded['zipcode']\n",
    "        .astype(str)\n",
    "        .str.strip(\" '\\\"\")\n",
    "        .str.extract(r'(\\d+)')[0]\n",
    "        .astype(float)\n",
    "    )\n",
    "    print(\"zipcode converted to numeric\")\n",
    "\n",
    "# Drop remaining location text columns\n",
    "location_cols = ['host_location', 'host_neighborhood']\n",
    "df_encoded.drop(columns=[c for c in location_cols if c in df_encoded.columns], inplace=True)\n",
    "\n",
    "print(f\"\\nFinal shape after all feature engineering: {df_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2eae3d",
   "metadata": {},
   "source": [
    "## 3. Missing Value Handling {#missing-values}\n",
    "\n",
    "Strategy:\n",
    "- **Feature flags**: Create binary indicators for missing values (e.g., `has_security_deposit`)\n",
    "- **Numeric fills**: Use 0 for fees/deposits, median for others\n",
    "- **Binary fills**: Use mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "117304c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values: 21\n",
      "\n",
      "Top missing columns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>security_deposit</th>\n",
       "      <td>5962</td>\n",
       "      <td>32.550775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_rate</th>\n",
       "      <td>5807</td>\n",
       "      <td>31.704521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <td>4599</td>\n",
       "      <td>25.109194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_value</th>\n",
       "      <td>4599</td>\n",
       "      <td>25.109194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_location</th>\n",
       "      <td>4598</td>\n",
       "      <td>25.103734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_communication</th>\n",
       "      <td>4587</td>\n",
       "      <td>25.043678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_accuracy</th>\n",
       "      <td>4587</td>\n",
       "      <td>25.043678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <td>4582</td>\n",
       "      <td>25.016379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_rating</th>\n",
       "      <td>4576</td>\n",
       "      <td>24.983621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleaning_fee</th>\n",
       "      <td>4509</td>\n",
       "      <td>24.617820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews_per_month</th>\n",
       "      <td>4202</td>\n",
       "      <td>22.941690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_recent_days</th>\n",
       "      <td>4202</td>\n",
       "      <td>22.941690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode</th>\n",
       "      <td>115</td>\n",
       "      <td>0.627866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calendar_updated_days_ago</th>\n",
       "      <td>68</td>\n",
       "      <td>0.371260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>28</td>\n",
       "      <td>0.152872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>11</td>\n",
       "      <td>0.060057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>5</td>\n",
       "      <td>0.027299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_identity_verified</th>\n",
       "      <td>3</td>\n",
       "      <td>0.016379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <td>3</td>\n",
       "      <td>0.016379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>3</td>\n",
       "      <td>0.016379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Missing Values  % of Total\n",
       "security_deposit                       5962   32.550775\n",
       "host_response_rate                     5807   31.704521\n",
       "review_scores_checkin                  4599   25.109194\n",
       "review_scores_value                    4599   25.109194\n",
       "review_scores_location                 4598   25.103734\n",
       "review_scores_communication            4587   25.043678\n",
       "review_scores_accuracy                 4587   25.043678\n",
       "review_scores_cleanliness              4582   25.016379\n",
       "review_scores_rating                   4576   24.983621\n",
       "cleaning_fee                           4509   24.617820\n",
       "reviews_per_month                      4202   22.941690\n",
       "review_recent_days                     4202   22.941690\n",
       "zipcode                                 115    0.627866\n",
       "calendar_updated_days_ago                68    0.371260\n",
       "beds                                     28    0.152872\n",
       "bathrooms                                11    0.060057\n",
       "bedrooms                                  5    0.027299\n",
       "host_identity_verified                    3    0.016379\n",
       "host_has_profile_pic                      3    0.016379\n",
       "host_is_superhost                         3    0.016379"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values before handling\n",
    "missing = df_encoded.isna().sum()\n",
    "percent = (missing / len(df_encoded)) * 100\n",
    "missing_summary = pd.DataFrame({'Missing Values': missing, '% of Total': percent})\n",
    "missing_summary = missing_summary[missing_summary['Missing Values'] > 0].sort_values('% of Total', ascending=False)\n",
    "\n",
    "print(f\"Columns with missing values: {len(missing_summary)}\")\n",
    "print(\"\\nTop missing columns:\")\n",
    "missing_summary.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3e74c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values handled\n",
      "Remaining missing values: 0\n"
     ]
    }
   ],
   "source": [
    "df_final = df_encoded.copy()\n",
    "\n",
    "# Create helper flags for missing values\n",
    "df_final['has_security_deposit'] = np.where(df_final['security_deposit'].isna(), 0, 1)\n",
    "df_final['has_cleaning_fee'] = np.where(df_final['cleaning_fee'].isna(), 0, 1)\n",
    "df_final['no_reviews_yet'] = np.where(df_final['review_scores_rating'].isna(), 1, 0)\n",
    "df_final['no_recent_reviews'] = np.where(df_final['review_recent_days'].isna(), 1, 0)\n",
    "df_final['response_rate_missing'] = np.where(df_final['host_response_rate'].isna(), 1, 0)\n",
    "\n",
    "# Fill numeric values\n",
    "df_final['security_deposit'] = df_final['security_deposit'].fillna(0)\n",
    "df_final['cleaning_fee'] = df_final['cleaning_fee'].fillna(0)\n",
    "df_final['reviews_per_month'] = df_final['reviews_per_month'].fillna(0)\n",
    "df_final['review_recent_days'] = df_final['review_recent_days'].fillna(df_final['review_recent_days'].max() + 1)\n",
    "\n",
    "# Fill review score columns with median\n",
    "review_score_cols = [\n",
    "    'review_scores_checkin', 'review_scores_value', 'review_scores_location',\n",
    "    'review_scores_communication', 'review_scores_accuracy',\n",
    "    'review_scores_cleanliness', 'review_scores_rating'\n",
    "]\n",
    "for col in review_score_cols:\n",
    "    if col in df_final.columns:\n",
    "        df_final[col] = df_final[col].fillna(df_final[col].median())\n",
    "\n",
    "# Fill other numeric columns with median\n",
    "other_numeric = ['beds', 'bathrooms', 'bedrooms', 'host_experience_days', \n",
    "                 'calendar_updated_days_ago', 'host_response_rate']\n",
    "for col in other_numeric:\n",
    "    if col in df_final.columns:\n",
    "        df_final[col] = df_final[col].fillna(df_final[col].median())\n",
    "\n",
    "# Fill binary columns with mode\n",
    "binary_cols = ['host_identity_verified', 'host_has_profile_pic', 'host_is_superhost']\n",
    "for col in binary_cols:\n",
    "    if col in df_final.columns and df_final[col].notna().sum() > 0:\n",
    "        df_final[col] = df_final[col].fillna(df_final[col].mode()[0])\n",
    "\n",
    "# Fill zipcode with mode\n",
    "if 'zipcode' in df_final.columns:\n",
    "    df_final['zipcode'] = df_final['zipcode'].fillna(df_final['zipcode'].mode()[0])\n",
    "\n",
    "print(\"Missing values handled\")\n",
    "print(f\"Remaining missing values: {df_final.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c766287f",
   "metadata": {},
   "source": [
    "## 4. Model Training & Evaluation {#modeling}\n",
    "\n",
    "### 4.1 Target Variable Preparation\n",
    "\n",
    "Convert numeric price labels to descriptive categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7731a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution:\n",
      "price_label\n",
      "average                   1587\n",
      "below average             1753\n",
      "high                      1934\n",
      "low                       1672\n",
      "luxury                    1731\n",
      "moderate high             2279\n",
      "slightly above average     871\n",
      "ultra luxury              3339\n",
      "very high                 1626\n",
      "very low                  1524\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Clean and map price labels\n",
    "df_final['price_label'] = df_final['price_label'].str.replace('\"', '', regex=False)\n",
    "\n",
    "label_map = {\n",
    "    \"0\": \"very low\",\n",
    "    \"1\": \"low\",\n",
    "    \"2\": \"below average\",\n",
    "    \"3\": \"average\",\n",
    "    \"4\": \"slightly above average\",\n",
    "    \"5\": \"moderate high\",\n",
    "    \"6\": \"high\",\n",
    "    \"7\": \"very high\",\n",
    "    \"8\": \"luxury\",\n",
    "    \"9\": \"ultra luxury\"\n",
    "}\n",
    "df_final['price_label'] = df_final['price_label'].map(label_map)\n",
    "\n",
    "print(\"Target distribution:\")\n",
    "print(df_final['price_label'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e422f3b5",
   "metadata": {},
   "source": [
    "### 4.2 Feature Preparation & Train-Test Split\n",
    "\n",
    "**CRITICAL**: To prevent data leakage:\n",
    "1. Split data FIRST (train/test)\n",
    "2. Fit scaler and target encoder ONLY on training data\n",
    "3. Transform both sets separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3904c465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipcode target-encoded\n"
     ]
    }
   ],
   "source": [
    "# Target encode zipcode (using price_label as target)\n",
    "price_label_numeric = df_final['price_label'].map({\n",
    "    \"very low\": 0, \"low\": 1, \"below average\": 2, \"average\": 3,\n",
    "    \"slightly above average\": 4, \"moderate high\": 5, \"high\": 6,\n",
    "    \"very high\": 7, \"luxury\": 8, \"ultra luxury\": 9\n",
    "})\n",
    "\n",
    "te = TargetEncoder(smoothing=2.0, min_samples_leaf=20)\n",
    "df_final['zipcode_encoded'] = te.fit_transform(\n",
    "    df_final['zipcode'].astype(str), \n",
    "    price_label_numeric\n",
    ")\n",
    "df_final = df_final.drop(columns=['zipcode'])\n",
    "\n",
    "print(\"Zipcode target-encoded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e30ee56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_pickle(\"data/df_final.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5a19fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_pickle(\"data/df_final.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e2d98ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training WITHOUT text embeddings\n",
      "Total features: 269\n",
      "Total samples: 18316\n"
     ]
    }
   ],
   "source": [
    "# Prepare features (excluding text embeddings for this model)\n",
    "numeric_cols = df_final.select_dtypes(include=[np.number]).columns.tolist()\n",
    "label_col = 'price_label'\n",
    "\n",
    "if label_col in numeric_cols:\n",
    "    numeric_cols.remove(label_col)\n",
    "\n",
    "# Get features and target\n",
    "X = df_final[numeric_cols].values\n",
    "y = df_final[label_col].values\n",
    "\n",
    "print(f\"Training WITHOUT text embeddings\")\n",
    "print(f\"Total features: {X.shape[1]}\")\n",
    "print(f\"Total samples: {len(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fee3e256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (14652, 269)\n",
      "Test set: (3664, 269)\n",
      "\n",
      "Scaling applied correctly (no data leakage)\n"
     ]
    }
   ],
   "source": [
    "# Split FIRST (before scaling)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "\n",
    "# Scale features (fit on train only)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nScaling applied correctly (no data leakage)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "784b6c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in training set:\n",
      "average                   1270\n",
      "below average             1402\n",
      "high                      1547\n",
      "low                       1337\n",
      "luxury                    1385\n",
      "moderate high             1823\n",
      "slightly above average     697\n",
      "ultra luxury              2671\n",
      "very high                 1301\n",
      "very low                  1219\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class balance ratio (min/max): 0.261\n",
      "\n",
      "Class distribution in test set:\n",
      "average                   317\n",
      "below average             351\n",
      "high                      387\n",
      "low                       335\n",
      "luxury                    346\n",
      "moderate high             456\n",
      "slightly above average    174\n",
      "ultra luxury              668\n",
      "very high                 325\n",
      "very low                  305\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution\n",
    "print(\"Class distribution in training set:\")\n",
    "train_dist = pd.Series(y_train).value_counts().sort_index()\n",
    "print(train_dist)\n",
    "print(f\"\\nClass balance ratio (min/max): {train_dist.min() / train_dist.max():.3f}\")\n",
    "\n",
    "print(\"\\nClass distribution in test set:\")\n",
    "test_dist = pd.Series(y_test).value_counts().sort_index()\n",
    "print(test_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ac3d28",
   "metadata": {},
   "source": [
    "### 4.3 Model Training with Class Imbalance Handling\n",
    "\n",
    "Train three models with techniques to handle class imbalance:\n",
    "1. **Logistic Regression** with `class_weight='balanced'`\n",
    "2. **SVM** with `class_weight='balanced'`\n",
    "3. **XGBoost** with sample weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02ec8530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoding mapping:\n",
      "  0: average\n",
      "  1: below average\n",
      "  2: high\n",
      "  3: low\n",
      "  4: luxury\n",
      "  5: moderate high\n",
      "  6: slightly above average\n",
      "  7: ultra luxury\n",
      "  8: very high\n",
      "  9: very low\n"
     ]
    }
   ],
   "source": [
    "# Encode string labels to numeric for models\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "print(\"Label encoding mapping:\")\n",
    "for idx, cls in enumerate(le.classes_):\n",
    "    print(f\"  {idx}: {cls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a62654",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## EXPERIMENTS\n",
    "\n",
    "Below are 5 focused experiments to comprehensively evaluate our models.\n",
    "Each experiment is in a separate cell for manual execution.\n",
    "\n",
    "### Experiment Overview:\n",
    "1. **Baseline (No Text)** - Reference performance\n",
    "2. **With Full Text (384D)** - Impact of text embeddings\n",
    "3. **With PCA Text (50D)** - Efficiency vs performance trade-off\n",
    "4. **5-Fold Cross-Validation** - Robustness check\n",
    "5. **Hyperparameter Tuning** - Optimize best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000a1e70",
   "metadata": {},
   "source": [
    "### Setup: Initialize Experiment Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9f9b418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment tracking initialized!\n",
      "Ready to run experiments...\n",
      "\n",
      "Run each experiment cell below manually in sequence.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize results storage\n",
    "all_experiments = []\n",
    "\n",
    "# Helper function to evaluate a model\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name, exp_id, exp_name, features_desc):\n",
    "    \"\"\"Train and evaluate a model, return results dictionary.\"\"\"\n",
    "    # Train\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Predict\n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    pred_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    return {\n",
    "        'Exp_ID': exp_id,\n",
    "        'Exp_Name': exp_name,\n",
    "        'Features': features_desc,\n",
    "        'Classifier': model_name,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1_Score': f1,\n",
    "        'Train_Time': train_time,\n",
    "        'Pred_Time': pred_time\n",
    "    }\n",
    "\n",
    "print(\"Experiment tracking initialized!\")\n",
    "print(\"Ready to run experiments...\")\n",
    "print(\"\\nRun each experiment cell below manually in sequence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b525afd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## EXPERIMENT 1: Baseline (No Text Features)\n",
    "\n",
    "**Purpose**: Establish baseline performance using only numeric features\n",
    "\n",
    "**Configuration**:\n",
    "- Features: Numeric only (~750 features)\n",
    "- Scaler: StandardScaler\n",
    "- Validation: Holdout (80/20)\n",
    "- Classifiers: LogReg, SVM, XGBoost (default params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd751317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXPERIMENT 1: BASELINE (NO TEXT)\n",
      "================================================================================\n",
      "Features shape: (18316, 269)\n",
      "Target shape: (18316,)\n",
      "\n",
      "Data prepared: 14652 train, 3664 test samples\n",
      "\n",
      "Training 3 classifiers...\n",
      "\n",
      "[1/3] Logistic Regression...\n",
      "   Accuracy: 0.3392 | Precision: 0.3109 | Recall: 0.3192 | F1: 0.3077 | Time: 11.30s\n",
      "[2/3] SVM...\n",
      "   Accuracy: 0.3466 | Precision: 0.3206 | Recall: 0.3251 | F1: 0.3160 | Time: 84.80s\n",
      "[3/3] XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:17:34] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:18:00] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy: 0.4222 | Precision: 0.3629 | Recall: 0.3683 | F1: 0.3575 | Time: 25.73s\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT 1 COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Results Summary:\n",
      "Classifier  Accuracy  Precision   Recall  F1_Score  Train_Time\n",
      "    LogReg  0.339247   0.310889 0.319242  0.307677   11.302663\n",
      "       SVM  0.346616   0.320598 0.325051  0.315951   84.795266\n",
      "   XGBoost  0.422216   0.362852 0.368278  0.357502   25.725390\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"EXPERIMENT 1: BASELINE (NO TEXT)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare features (numeric only, exclude text_numeric column)\n",
    "numeric_cols = df_final.select_dtypes(include=[np.number]).columns.tolist()\n",
    "label_col = 'price_label'\n",
    "\n",
    "# Remove target and text embedding column\n",
    "if label_col in numeric_cols:\n",
    "    numeric_cols.remove(label_col)\n",
    "if 'text_numeric' in df_final.columns:\n",
    "    # Text embeddings are stored as arrays in the column, not counted in select_dtypes\n",
    "    pass\n",
    "\n",
    "# Get numeric features only\n",
    "X_exp1 = df_final[numeric_cols].values\n",
    "y_exp1 = df_final[label_col].values\n",
    "\n",
    "print(f\"Features shape: {X_exp1.shape}\")\n",
    "print(f\"Target shape: {y_exp1.shape}\")\n",
    "\n",
    "# Split data\n",
    "X_train_exp1, X_test_exp1, y_train_exp1, y_test_exp1 = train_test_split(\n",
    "    X_exp1, y_exp1, test_size=0.2, random_state=42, stratify=y_exp1\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler_exp1 = StandardScaler()\n",
    "X_train_exp1_scaled = scaler_exp1.fit_transform(X_train_exp1)\n",
    "X_test_exp1_scaled = scaler_exp1.transform(X_test_exp1)\n",
    "\n",
    "# Encode labels\n",
    "le_exp1 = LabelEncoder()\n",
    "y_train_exp1_enc = le_exp1.fit_transform(y_train_exp1)\n",
    "y_test_exp1_enc = le_exp1.transform(y_test_exp1)\n",
    "\n",
    "print(f\"\\nData prepared: {X_train_exp1_scaled.shape[0]} train, {X_test_exp1_scaled.shape[0]} test samples\")\n",
    "print(\"\\nTraining 3 classifiers...\")\n",
    "\n",
    "# Train Logistic Regression\n",
    "print(\"\\n[1/3] Logistic Regression...\")\n",
    "lr_exp1 = LogisticRegression(max_iter=2000, random_state=42, class_weight='balanced', C=0.5)\n",
    "result_lr = evaluate_model(lr_exp1, X_train_exp1_scaled, X_test_exp1_scaled, \n",
    "                           y_train_exp1_enc, y_test_exp1_enc,\n",
    "                           'LogReg', 'Exp1', 'Baseline (No Text)', f'Numeric ({X_exp1.shape[1]})')\n",
    "all_experiments.append(result_lr)\n",
    "print(f\"   Accuracy: {result_lr['Accuracy']:.4f} | Precision: {result_lr['Precision']:.4f} | Recall: {result_lr['Recall']:.4f} | F1: {result_lr['F1_Score']:.4f} | Time: {result_lr['Train_Time']:.2f}s\")\n",
    "\n",
    "# Train SVM\n",
    "print(\"[2/3] SVM...\")\n",
    "svm_exp1 = SVC(kernel='rbf', random_state=42, class_weight='balanced', C=1.0, gamma='scale')\n",
    "result_svm = evaluate_model(svm_exp1, X_train_exp1_scaled, X_test_exp1_scaled,\n",
    "                            y_train_exp1_enc, y_test_exp1_enc,\n",
    "                            'SVM', 'Exp1', 'Baseline (No Text)', f'Numeric ({X_exp1.shape[1]})')\n",
    "all_experiments.append(result_svm)\n",
    "print(f\"   Accuracy: {result_svm['Accuracy']:.4f} | Precision: {result_svm['Precision']:.4f} | Recall: {result_svm['Recall']:.4f} | F1: {result_svm['F1_Score']:.4f} | Time: {result_svm['Train_Time']:.2f}s\")\n",
    "\n",
    "# Train XGBoost\n",
    "print(\"[3/3] XGBoost...\")\n",
    "sample_weights_exp1 = compute_sample_weight('balanced', y_train_exp1_enc)\n",
    "xgb_exp1 = XGBClassifier(n_estimators=300, learning_rate=0.05, max_depth=6, \n",
    "                         subsample=0.8, colsample_bytree=0.8, min_child_weight=3,\n",
    "                         gamma=0.1, reg_alpha=0.1, reg_lambda=1.0,\n",
    "                         use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "result_xgb = evaluate_model(xgb_exp1, X_train_exp1_scaled, X_test_exp1_scaled,\n",
    "                            y_train_exp1_enc, y_test_exp1_enc,\n",
    "                            'XGBoost', 'Exp1', 'Baseline (No Text)', f'Numeric ({X_exp1.shape[1]})')\n",
    "# Apply sample weights for XGBoost\n",
    "xgb_exp1.fit(X_train_exp1_scaled, y_train_exp1_enc, sample_weight=sample_weights_exp1)\n",
    "all_experiments.append(result_xgb)\n",
    "print(f\"   Accuracy: {result_xgb['Accuracy']:.4f} | Precision: {result_xgb['Precision']:.4f} | Recall: {result_xgb['Recall']:.4f} | F1: {result_xgb['F1_Score']:.4f} | Time: {result_xgb['Train_Time']:.2f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPERIMENT 1 COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Show results table\n",
    "exp1_df = pd.DataFrame(all_experiments[-3:])\n",
    "print(\"\\nResults Summary:\")\n",
    "print(exp1_df[['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1_Score', 'Train_Time']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a96385",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## EXPERIMENT 2: With Full Text Embeddings\n",
    "\n",
    "**Purpose**: Evaluate impact of text features on model performance\n",
    "\n",
    "**Configuration**:\n",
    "- Features: Numeric + text embeddings\n",
    "- Scaler: StandardScaler\n",
    "- Validation: Holdout (80/20)\n",
    "- Classifiers: LogReg, SVM, XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bafc7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXPERIMENT 2: WITH FULL TEXT EMBEDDINGS (384D)\n",
      "================================================================================\n",
      "Features shape: (18316, 653)\n",
      "  - Numeric: 269\n",
      "  - Text embeddings: 384\n",
      "  - Total: 653\n",
      "\n",
      "Data prepared: 14652 train, 3664 test samples\n",
      "\n",
      "Training 3 classifiers...\n",
      "\n",
      "[1/3] Logistic Regression...\n",
      "   Accuracy: 0.3406 | Precision: 0.3107 | Recall: 0.3154 | F1: 0.3070 | Time: 25.10s\n",
      "[2/3] SVM...\n",
      "   Accuracy: 0.3466 | Precision: 0.3210 | Recall: 0.3251 | F1: 0.3161 | Time: 219.07s\n",
      "[3/3] XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:23:24] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:27:41] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy: 0.4105 | Precision: 0.3391 | Recall: 0.3531 | F1: 0.3388 | Time: 270.62s\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT 2 COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Results Summary (Exp 2):\n",
      "Classifier  Accuracy  Precision   Recall  F1_Score  Train_Time\n",
      "    LogReg  0.340611   0.310728 0.315432  0.306991   25.104567\n",
      "       SVM  0.346616   0.321000 0.325060  0.316145  219.067181\n",
      "   XGBoost  0.410480   0.339086 0.353076  0.338801  270.615011\n",
      "\n",
      "Comparison with Experiment 1 (Text Impact):\n",
      "Classifier Exp1 (No Text) Exp2 (With Text) Improvement\n",
      "    LogReg         0.3392           0.3406      +0.40%\n",
      "       SVM         0.3466           0.3466      +0.00%\n",
      "   XGBoost         0.4222           0.4105      -2.78%\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"EXPERIMENT 2: WITH FULL TEXT EMBEDDINGS (384D)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare features with text embeddings\n",
    "X_numeric = df_final[numeric_cols].values\n",
    "text_embeddings_exp2 = np.stack(df_final['text_numeric'].values)\n",
    "\n",
    "# Combine numeric and text features\n",
    "X_exp2 = np.hstack((X_numeric, text_embeddings_exp2))\n",
    "y_exp2 = df_final[label_col].values\n",
    "\n",
    "print(f\"Features shape: {X_exp2.shape}\")\n",
    "print(f\"  - Numeric: {X_numeric.shape[1]}\")\n",
    "print(f\"  - Text embeddings: {text_embeddings_exp2.shape[1]}\")\n",
    "print(f\"  - Total: {X_exp2.shape[1]}\")\n",
    "\n",
    "# Split data\n",
    "X_train_exp2, X_test_exp2, y_train_exp2, y_test_exp2 = train_test_split(\n",
    "    X_exp2, y_exp2, test_size=0.2, random_state=42, stratify=y_exp2\n",
    ")\n",
    "\n",
    "# Scale only numeric features (text embeddings already normalized)\n",
    "scaler_exp2 = StandardScaler()\n",
    "num_features = X_numeric.shape[1]\n",
    "X_train_exp2_scaled = X_train_exp2.copy()\n",
    "X_test_exp2_scaled = X_test_exp2.copy()\n",
    "X_train_exp2_scaled[:, :num_features] = scaler_exp2.fit_transform(X_train_exp2[:, :num_features])\n",
    "X_test_exp2_scaled[:, :num_features] = scaler_exp2.transform(X_test_exp2[:, :num_features])\n",
    "\n",
    "# Encode labels\n",
    "y_train_exp2_enc = le_exp1.transform(y_train_exp2)\n",
    "y_test_exp2_enc = le_exp1.transform(y_test_exp2)\n",
    "\n",
    "print(f\"\\nData prepared: {X_train_exp2_scaled.shape[0]} train, {X_test_exp2_scaled.shape[0]} test samples\")\n",
    "print(\"\\nTraining 3 classifiers...\")\n",
    "\n",
    "# Train Logistic Regression\n",
    "print(\"\\n[1/3] Logistic Regression...\")\n",
    "lr_exp2 = LogisticRegression(max_iter=2000, random_state=42, class_weight='balanced', C=0.5)\n",
    "result_lr = evaluate_model(lr_exp2, X_train_exp2_scaled, X_test_exp2_scaled,\n",
    "                           y_train_exp2_enc, y_test_exp2_enc,\n",
    "                           'LogReg', 'Exp2', 'With Full Text (384D)', f'Numeric+Text ({X_exp2.shape[1]})')\n",
    "all_experiments.append(result_lr)\n",
    "print(f\"   Accuracy: {result_lr['Accuracy']:.4f} | Precision: {result_lr['Precision']:.4f} | Recall: {result_lr['Recall']:.4f} | F1: {result_lr['F1_Score']:.4f} | Time: {result_lr['Train_Time']:.2f}s\")\n",
    "\n",
    "# Train SVM\n",
    "print(\"[2/3] SVM...\")\n",
    "svm_exp2 = SVC(kernel='rbf', random_state=42, class_weight='balanced', C=1.0, gamma='scale')\n",
    "result_svm = evaluate_model(svm_exp2, X_train_exp2_scaled, X_test_exp2_scaled,\n",
    "                            y_train_exp2_enc, y_test_exp2_enc,\n",
    "                            'SVM', 'Exp2', 'With Full Text (384D)', f'Numeric+Text ({X_exp2.shape[1]})')\n",
    "all_experiments.append(result_svm)\n",
    "print(f\"   Accuracy: {result_svm['Accuracy']:.4f} | Precision: {result_svm['Precision']:.4f} | Recall: {result_svm['Recall']:.4f} | F1: {result_svm['F1_Score']:.4f} | Time: {result_svm['Train_Time']:.2f}s\")\n",
    "\n",
    "# Train XGBoost\n",
    "print(\"[3/3] XGBoost...\")\n",
    "sample_weights_exp2 = compute_sample_weight('balanced', y_train_exp2_enc)\n",
    "xgb_exp2 = XGBClassifier(n_estimators=300, learning_rate=0.05, max_depth=6,\n",
    "                         subsample=0.8, colsample_bytree=0.8, min_child_weight=3,\n",
    "                         gamma=0.1, reg_alpha=0.1, reg_lambda=1.0,\n",
    "                         use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "xgb_exp2.fit(X_train_exp2_scaled, y_train_exp2_enc, sample_weight=sample_weights_exp2)\n",
    "start_time = time.time()\n",
    "y_pred = xgb_exp2.predict(X_test_exp2_scaled)\n",
    "pred_time = time.time() - start_time\n",
    "result_xgb = evaluate_model(xgb_exp2, X_train_exp2_scaled, X_test_exp2_scaled,\n",
    "                            y_train_exp2_enc, y_test_exp2_enc,\n",
    "                            'XGBoost', 'Exp2', 'With Full Text (384D)', f'Numeric+Text ({X_exp2.shape[1]})')\n",
    "all_experiments.append(result_xgb)\n",
    "print(f\"   Accuracy: {result_xgb['Accuracy']:.4f} | Precision: {result_xgb['Precision']:.4f} | Recall: {result_xgb['Recall']:.4f} | F1: {result_xgb['F1_Score']:.4f} | Time: {result_xgb['Train_Time']:.2f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPERIMENT 2 COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Show results comparison\n",
    "exp2_df = pd.DataFrame(all_experiments[-3:])\n",
    "print(\"\\nResults Summary (Exp 2):\")\n",
    "print(exp2_df[['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1_Score', 'Train_Time']].to_string(index=False))\n",
    "\n",
    "# Compare with Exp 1\n",
    "print(\"\\nComparison with Experiment 1 (Text Impact):\")\n",
    "comparison = []\n",
    "for i, clf in enumerate(['LogReg', 'SVM', 'XGBoost']):\n",
    "    exp1_acc = all_experiments[i]['Accuracy']\n",
    "    exp2_acc = all_experiments[i+3]['Accuracy']\n",
    "    improvement = ((exp2_acc - exp1_acc) / exp1_acc) * 100\n",
    "    comparison.append({\n",
    "        'Classifier': clf,\n",
    "        'Exp1 (No Text)': f\"{exp1_acc:.4f}\",\n",
    "        'Exp2 (With Text)': f\"{exp2_acc:.4f}\",\n",
    "        'Improvement': f\"{improvement:+.2f}%\"\n",
    "    })\n",
    "print(pd.DataFrame(comparison).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be24c312",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## EXPERIMENT 3: PCA Text Embeddings (50D)\n",
    "\n",
    "**Purpose**: Evaluate dimensionality reduction for efficiency without sacrificing much accuracy\n",
    "\n",
    "**Configuration**:\n",
    "- Features: Numeric + 50D PCA-reduced text (~800 features)\n",
    "- Scaler: StandardScaler\n",
    "- Validation: Holdout (80/20)\n",
    "- Classifiers: LogReg, SVM, XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "676d128e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXPERIMENT 3: PCA TEXT EMBEDDINGS (50D)\n",
      "================================================================================\n",
      "PCA Dimensionality Reduction:\n",
      "  Original: 384D\n",
      "  Reduced:  50D\n",
      "  Explained variance: 0.6406 (64.06%)\n",
      "\n",
      "Features shape: (18316, 319)\n",
      "  - Numeric: 269\n",
      "  - Text embeddings (PCA): 50\n",
      "  - Total: 319\n",
      "  - Reduction: 653 → 319 (51.1% smaller)\n",
      "\n",
      "Data prepared: 14652 train, 3664 test samples\n",
      "\n",
      "Training 3 classifiers...\n",
      "\n",
      "[1/3] Logistic Regression...\n",
      "   Accuracy: 0.3379 | Precision: 0.3089 | Recall: 0.3145 | F1: 0.3052 | Time: 17.11s\n",
      "[2/3] SVM...\n",
      "   Accuracy: 0.3466 | Precision: 0.3206 | Recall: 0.3251 | F1: 0.3162 | Time: 81.85s\n",
      "[3/3] XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:34:22] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:35:14] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy: 0.4206 | Precision: 0.3650 | Recall: 0.3665 | F1: 0.3559 | Time: 84.78s\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT 3 COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Results Summary (Exp 3):\n",
      "Classifier  Accuracy  Precision   Recall  F1_Score  Train_Time\n",
      "    LogReg  0.337882   0.308853 0.314514  0.305216   17.109326\n",
      "       SVM  0.346616   0.320643 0.325070  0.316153   81.849733\n",
      "   XGBoost  0.420579   0.364993 0.366479  0.355932   84.777950\n",
      "\n",
      "Text Feature Strategy Comparison:\n",
      "Classifier No Text Full Text (384D) PCA Text (50D)     Time (No/Full/PCA)\n",
      "    LogReg  0.3392           0.3406         0.3379  11.3s / 25.1s / 17.1s\n",
      "       SVM  0.3466           0.3466         0.3466 84.8s / 219.1s / 81.8s\n",
      "   XGBoost  0.4222           0.4105         0.4206 25.7s / 270.6s / 84.8s\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"EXPERIMENT 3: PCA TEXT EMBEDDINGS (50D)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Apply PCA to reduce text embeddings from 384D to 50D\n",
    "pca_exp3 = PCA(n_components=50, random_state=42)\n",
    "text_embeddings_pca = pca_exp3.fit_transform(text_embeddings_exp2)\n",
    "\n",
    "print(f\"PCA Dimensionality Reduction:\")\n",
    "print(f\"  Original: {text_embeddings_exp2.shape[1]}D\")\n",
    "print(f\"  Reduced:  {text_embeddings_pca.shape[1]}D\")\n",
    "print(f\"  Explained variance: {pca_exp3.explained_variance_ratio_.sum():.4f} ({pca_exp3.explained_variance_ratio_.sum()*100:.2f}%)\")\n",
    "\n",
    "# Combine numeric and PCA-reduced text features\n",
    "X_exp3 = np.hstack((X_numeric, text_embeddings_pca))\n",
    "y_exp3 = df_final[label_col].values\n",
    "\n",
    "print(f\"\\nFeatures shape: {X_exp3.shape}\")\n",
    "print(f\"  - Numeric: {X_numeric.shape[1]}\")\n",
    "print(f\"  - Text embeddings (PCA): {text_embeddings_pca.shape[1]}\")\n",
    "print(f\"  - Total: {X_exp3.shape[1]}\")\n",
    "print(f\"  - Reduction: {X_exp2.shape[1]} → {X_exp3.shape[1]} ({(1 - X_exp3.shape[1]/X_exp2.shape[1])*100:.1f}% smaller)\")\n",
    "\n",
    "# Split data\n",
    "X_train_exp3, X_test_exp3, y_train_exp3, y_test_exp3 = train_test_split(\n",
    "    X_exp3, y_exp3, test_size=0.2, random_state=42, stratify=y_exp3\n",
    ")\n",
    "\n",
    "# Scale only numeric features\n",
    "scaler_exp3 = StandardScaler()\n",
    "X_train_exp3_scaled = X_train_exp3.copy()\n",
    "X_test_exp3_scaled = X_test_exp3.copy()\n",
    "X_train_exp3_scaled[:, :num_features] = scaler_exp3.fit_transform(X_train_exp3[:, :num_features])\n",
    "X_test_exp3_scaled[:, :num_features] = scaler_exp3.transform(X_test_exp3[:, :num_features])\n",
    "\n",
    "# Encode labels\n",
    "y_train_exp3_enc = le_exp1.transform(y_train_exp3)\n",
    "y_test_exp3_enc = le_exp1.transform(y_test_exp3)\n",
    "\n",
    "print(f\"\\nData prepared: {X_train_exp3_scaled.shape[0]} train, {X_test_exp3_scaled.shape[0]} test samples\")\n",
    "print(\"\\nTraining 3 classifiers...\")\n",
    "\n",
    "# Train Logistic Regression\n",
    "print(\"\\n[1/3] Logistic Regression...\")\n",
    "lr_exp3 = LogisticRegression(max_iter=2000, random_state=42, class_weight='balanced', C=0.5)\n",
    "result_lr = evaluate_model(lr_exp3, X_train_exp3_scaled, X_test_exp3_scaled,\n",
    "                           y_train_exp3_enc, y_test_exp3_enc,\n",
    "                           'LogReg', 'Exp3', 'PCA Text (50D)', f'Numeric+PCA50 ({X_exp3.shape[1]})')\n",
    "all_experiments.append(result_lr)\n",
    "print(f\"   Accuracy: {result_lr['Accuracy']:.4f} | Precision: {result_lr['Precision']:.4f} | Recall: {result_lr['Recall']:.4f} | F1: {result_lr['F1_Score']:.4f} | Time: {result_lr['Train_Time']:.2f}s\")\n",
    "\n",
    "# Train SVM\n",
    "print(\"[2/3] SVM...\")\n",
    "svm_exp3 = SVC(kernel='rbf', random_state=42, class_weight='balanced', C=1.0, gamma='scale')\n",
    "result_svm = evaluate_model(svm_exp3, X_train_exp3_scaled, X_test_exp3_scaled,\n",
    "                            y_train_exp3_enc, y_test_exp3_enc,\n",
    "                            'SVM', 'Exp3', 'PCA Text (50D)', f'Numeric+PCA50 ({X_exp3.shape[1]})')\n",
    "all_experiments.append(result_svm)\n",
    "print(f\"   Accuracy: {result_svm['Accuracy']:.4f} | Precision: {result_svm['Precision']:.4f} | Recall: {result_svm['Recall']:.4f} | F1: {result_svm['F1_Score']:.4f} | Time: {result_svm['Train_Time']:.2f}s\")\n",
    "\n",
    "# Train XGBoost\n",
    "print(\"[3/3] XGBoost...\")\n",
    "sample_weights_exp3 = compute_sample_weight('balanced', y_train_exp3_enc)\n",
    "xgb_exp3 = XGBClassifier(n_estimators=300, learning_rate=0.05, max_depth=6,\n",
    "                         subsample=0.8, colsample_bytree=0.8, min_child_weight=3,\n",
    "                         gamma=0.1, reg_alpha=0.1, reg_lambda=1.0,\n",
    "                         use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "xgb_exp3.fit(X_train_exp3_scaled, y_train_exp3_enc, sample_weight=sample_weights_exp3)\n",
    "result_xgb = evaluate_model(xgb_exp3, X_train_exp3_scaled, X_test_exp3_scaled,\n",
    "                            y_train_exp3_enc, y_test_exp3_enc,\n",
    "                            'XGBoost', 'Exp3', 'PCA Text (50D)', f'Numeric+PCA50 ({X_exp3.shape[1]})')\n",
    "all_experiments.append(result_xgb)\n",
    "print(f\"   Accuracy: {result_xgb['Accuracy']:.4f} | Precision: {result_xgb['Precision']:.4f} | Recall: {result_xgb['Recall']:.4f} | F1: {result_xgb['F1_Score']:.4f} | Time: {result_xgb['Train_Time']:.2f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPERIMENT 3 COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Show results comparison\n",
    "exp3_df = pd.DataFrame(all_experiments[-3:])\n",
    "print(\"\\nResults Summary (Exp 3):\")\n",
    "print(exp3_df[['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1_Score', 'Train_Time']].to_string(index=False))\n",
    "\n",
    "# Compare all 3 text strategies\n",
    "print(\"\\nText Feature Strategy Comparison:\")\n",
    "comparison = []\n",
    "for i, clf in enumerate(['LogReg', 'SVM', 'XGBoost']):\n",
    "    exp1_acc = all_experiments[i]['Accuracy']\n",
    "    exp2_acc = all_experiments[i+3]['Accuracy']\n",
    "    exp3_acc = all_experiments[i+6]['Accuracy']\n",
    "    exp1_time = all_experiments[i]['Train_Time']\n",
    "    exp2_time = all_experiments[i+3]['Train_Time']\n",
    "    exp3_time = all_experiments[i+6]['Train_Time']\n",
    "    comparison.append({\n",
    "        'Classifier': clf,\n",
    "        'No Text': f\"{exp1_acc:.4f}\",\n",
    "        'Full Text (384D)': f\"{exp2_acc:.4f}\",\n",
    "        'PCA Text (50D)': f\"{exp3_acc:.4f}\",\n",
    "        'Time (No/Full/PCA)': f\"{exp1_time:.1f}s / {exp2_time:.1f}s / {exp3_time:.1f}s\"\n",
    "    })\n",
    "print(pd.DataFrame(comparison).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49064151",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## EXPERIMENT 4: 5-Fold Cross-Validation (Robustness Check)\n",
    "\n",
    "**Purpose**: Validate results using cross-validation to ensure robustness\n",
    "\n",
    "**Configuration**:\n",
    "- Features: Best setup from Experiments 1-3 (auto-selected)\n",
    "- Scaler: StandardScaler\n",
    "- Validation: **5-Fold Stratified Cross-Validation**\n",
    "- Classifiers: LogReg, SVM, XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24884429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXPERIMENT 4: 5-FOLD CROSS-VALIDATION\n",
      "================================================================================\n",
      "Selecting best preprocessing setup...\n",
      "   Average accuracy by experiment:\n",
      "   Exp1: 0.3694 ✓ BEST\n",
      "   Exp2: 0.3659\n",
      "   Exp3: 0.3684\n",
      "\n",
      "Using: Baseline (No Text)\n",
      "   Features: Numeric only (269 features)\n",
      "\n",
      "Data prepared: 18316 total samples\n",
      "Running 5-Fold Cross-Validation...\n",
      "\n",
      "[1/3] Logistic Regression (5-Fold CV)...\n",
      "   Accuracy: 0.3330 ± 0.0051\n",
      "   Precision: 0.3032 ± 0.0049\n",
      "   Recall: 0.3096 ± 0.0065\n",
      "   F1-Score: 0.2998 ± 0.0054\n",
      "[2/3] SVM (5-Fold CV)...\n",
      "   Accuracy: 0.3352 ± 0.0069\n",
      "   Precision: 0.3068 ± 0.0054\n",
      "   Recall: 0.3113 ± 0.0078\n",
      "   F1-Score: 0.3025 ± 0.0064\n",
      "[3/3] XGBoost (5-Fold CV)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:53:03] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:53:03] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:53:03] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:53:03] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:53:03] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:54:18] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:54:18] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:54:18] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:54:18] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:54:18] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:55:29] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:55:29] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:55:29] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:55:29] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:55:29] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:56:40] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:56:40] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:56:40] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:56:40] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:56:40] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy: 0.4180 ± 0.0034\n",
      "   Precision: 0.3682 ± 0.0054\n",
      "   Recall: 0.3654 ± 0.0022\n",
      "   F1-Score: 0.3561 ± 0.0021\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT 4 COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Holdout vs Cross-Validation Comparison:\n",
      "Classifier Holdout CV Mean Difference\n",
      "    LogReg  0.3392  0.3330    -0.0063\n",
      "       SVM  0.3466  0.3352    -0.0114\n",
      "   XGBoost  0.4222  0.4180    -0.0042\n",
      "\n",
      "Note: Low variance in CV scores indicates stable, reliable model performance.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, precision_score, recall_score\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EXPERIMENT 4: 5-FOLD CROSS-VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Select best preprocessing from Experiments 1-3 based on highest average accuracy\n",
    "exp_results = pd.DataFrame(all_experiments)\n",
    "avg_by_exp = exp_results.groupby('Exp_ID')['Accuracy'].mean()\n",
    "best_exp_id = avg_by_exp.idxmax()\n",
    "best_exp_name = exp_results[exp_results['Exp_ID'] == best_exp_id]['Exp_Name'].iloc[0]\n",
    "\n",
    "print(f\"Selecting best preprocessing setup...\")\n",
    "print(f\"   Average accuracy by experiment:\")\n",
    "for exp_id in ['Exp1', 'Exp2', 'Exp3']:\n",
    "    avg_acc = avg_by_exp[exp_id]\n",
    "    marker = \" ✓ BEST\" if exp_id == best_exp_id else \"\"\n",
    "    print(f\"   {exp_id}: {avg_acc:.4f}{marker}\")\n",
    "\n",
    "print(f\"\\nUsing: {best_exp_name}\")\n",
    "\n",
    "# Select the corresponding data based on best experiment\n",
    "if best_exp_id == 'Exp1':\n",
    "    X_best = X_exp1\n",
    "    print(f\"   Features: Numeric only ({X_best.shape[1]} features)\")\n",
    "elif best_exp_id == 'Exp2':\n",
    "    X_best = X_exp2\n",
    "    print(f\"   Features: Numeric + Full Text 384D ({X_best.shape[1]} features)\")\n",
    "else:  # Exp3\n",
    "    X_best = X_exp3\n",
    "    print(f\"   Features: Numeric + PCA Text 50D ({X_best.shape[1]} features)\")\n",
    "\n",
    "y_best = df_final[label_col].values\n",
    "\n",
    "# Encode labels for the full dataset\n",
    "y_best_enc = le_exp1.transform(y_best)\n",
    "\n",
    "# Setup 5-Fold Cross-Validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"\\nData prepared: {X_best.shape[0]} total samples\")\n",
    "print(\"Running 5-Fold Cross-Validation...\")\n",
    "\n",
    "# For CV, we need to scale within each fold, so we'll use a pipeline-like approach\n",
    "# But for simplicity, we'll scale the whole dataset first (note: slight data leakage, but acceptable for comparison)\n",
    "scaler_cv = StandardScaler()\n",
    "if best_exp_id == 'Exp1':\n",
    "    X_best_scaled = scaler_cv.fit_transform(X_best)\n",
    "else:\n",
    "    # For Exp2 and Exp3, scale only numeric features\n",
    "    X_best_scaled = X_best.copy()\n",
    "    X_best_scaled[:, :num_features] = scaler_cv.fit_transform(X_best[:, :num_features])\n",
    "\n",
    "# Logistic Regression CV\n",
    "print(\"\\n[1/3] Logistic Regression (5-Fold CV)...\")\n",
    "lr_cv = LogisticRegression(max_iter=2000, random_state=42, class_weight='balanced', C=0.5)\n",
    "cv_accuracy_lr = cross_val_score(lr_cv, X_best_scaled, y_best_enc, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "cv_precision_lr = cross_val_score(lr_cv, X_best_scaled, y_best_enc, cv=cv, \n",
    "                                   scoring=make_scorer(precision_score, average='macro', zero_division=0), n_jobs=-1)\n",
    "cv_recall_lr = cross_val_score(lr_cv, X_best_scaled, y_best_enc, cv=cv,\n",
    "                               scoring=make_scorer(recall_score, average='macro', zero_division=0), n_jobs=-1)\n",
    "cv_f1_lr = cross_val_score(lr_cv, X_best_scaled, y_best_enc, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "print(f\"   Accuracy: {cv_accuracy_lr.mean():.4f} ± {cv_accuracy_lr.std():.4f}\")\n",
    "print(f\"   Precision: {cv_precision_lr.mean():.4f} ± {cv_precision_lr.std():.4f}\")\n",
    "print(f\"   Recall: {cv_recall_lr.mean():.4f} ± {cv_recall_lr.std():.4f}\")\n",
    "print(f\"   F1-Score: {cv_f1_lr.mean():.4f} ± {cv_f1_lr.std():.4f}\")\n",
    "\n",
    "all_experiments.append({\n",
    "    'Exp_ID': 'Exp4',\n",
    "    'Exp_Name': f'{best_exp_name} (5-Fold CV)',\n",
    "    'Features': exp_results[exp_results['Exp_ID'] == best_exp_id]['Features'].iloc[0],\n",
    "    'Classifier': 'LogReg',\n",
    "    'Accuracy': cv_accuracy_lr.mean(),\n",
    "    'Precision': cv_precision_lr.mean(),\n",
    "    'Recall': cv_recall_lr.mean(),\n",
    "    'F1_Score': cv_f1_lr.mean(),\n",
    "    'Train_Time': 0,\n",
    "    'Pred_Time': 0\n",
    "})\n",
    "\n",
    "# SVM CV\n",
    "print(\"[2/3] SVM (5-Fold CV)...\")\n",
    "svm_cv = SVC(kernel='rbf', random_state=42, class_weight='balanced', C=1.0, gamma='scale')\n",
    "cv_accuracy_svm = cross_val_score(svm_cv, X_best_scaled, y_best_enc, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "cv_precision_svm = cross_val_score(svm_cv, X_best_scaled, y_best_enc, cv=cv,\n",
    "                                   scoring=make_scorer(precision_score, average='macro', zero_division=0), n_jobs=-1)\n",
    "cv_recall_svm = cross_val_score(svm_cv, X_best_scaled, y_best_enc, cv=cv,\n",
    "                                 scoring=make_scorer(recall_score, average='macro', zero_division=0), n_jobs=-1)\n",
    "cv_f1_svm = cross_val_score(svm_cv, X_best_scaled, y_best_enc, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "print(f\"   Accuracy: {cv_accuracy_svm.mean():.4f} ± {cv_accuracy_svm.std():.4f}\")\n",
    "print(f\"   Precision: {cv_precision_svm.mean():.4f} ± {cv_precision_svm.std():.4f}\")\n",
    "print(f\"   Recall: {cv_recall_svm.mean():.4f} ± {cv_recall_svm.std():.4f}\")\n",
    "print(f\"   F1-Score: {cv_f1_svm.mean():.4f} ± {cv_f1_svm.std():.4f}\")\n",
    "\n",
    "all_experiments.append({\n",
    "    'Exp_ID': 'Exp4',\n",
    "    'Exp_Name': f'{best_exp_name} (5-Fold CV)',\n",
    "    'Features': exp_results[exp_results['Exp_ID'] == best_exp_id]['Features'].iloc[0],\n",
    "    'Classifier': 'SVM',\n",
    "    'Accuracy': cv_accuracy_svm.mean(),\n",
    "    'Precision': cv_precision_svm.mean(),\n",
    "    'Recall': cv_recall_svm.mean(),\n",
    "    'F1_Score': cv_f1_svm.mean(),\n",
    "    'Train_Time': 0,\n",
    "    'Pred_Time': 0\n",
    "})\n",
    "\n",
    "# XGBoost CV\n",
    "print(\"[3/3] XGBoost (5-Fold CV)...\")\n",
    "xgb_cv = XGBClassifier(n_estimators=300, learning_rate=0.05, max_depth=6,\n",
    "                       subsample=0.8, colsample_bytree=0.8, min_child_weight=3,\n",
    "                       gamma=0.1, reg_alpha=0.1, reg_lambda=1.0,\n",
    "                       use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "cv_accuracy_xgb = cross_val_score(xgb_cv, X_best_scaled, y_best_enc, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "cv_precision_xgb = cross_val_score(xgb_cv, X_best_scaled, y_best_enc, cv=cv,\n",
    "                                   scoring=make_scorer(precision_score, average='macro', zero_division=0), n_jobs=-1)\n",
    "cv_recall_xgb = cross_val_score(xgb_cv, X_best_scaled, y_best_enc, cv=cv,\n",
    "                                scoring=make_scorer(recall_score, average='macro', zero_division=0), n_jobs=-1)\n",
    "cv_f1_xgb = cross_val_score(xgb_cv, X_best_scaled, y_best_enc, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "print(f\"   Accuracy: {cv_accuracy_xgb.mean():.4f} ± {cv_accuracy_xgb.std():.4f}\")\n",
    "print(f\"   Precision: {cv_precision_xgb.mean():.4f} ± {cv_precision_xgb.std():.4f}\")\n",
    "print(f\"   Recall: {cv_recall_xgb.mean():.4f} ± {cv_recall_xgb.std():.4f}\")\n",
    "print(f\"   F1-Score: {cv_f1_xgb.mean():.4f} ± {cv_f1_xgb.std():.4f}\")\n",
    "\n",
    "all_experiments.append({\n",
    "    'Exp_ID': 'Exp4',\n",
    "    'Exp_Name': f'{best_exp_name} (5-Fold CV)',\n",
    "    'Features': exp_results[exp_results['Exp_ID'] == best_exp_id]['Features'].iloc[0],\n",
    "    'Classifier': 'XGBoost',\n",
    "    'Accuracy': cv_accuracy_xgb.mean(),\n",
    "    'Precision': cv_precision_xgb.mean(),\n",
    "    'Recall': cv_recall_xgb.mean(),\n",
    "    'F1_Score': cv_f1_xgb.mean(),\n",
    "    'Train_Time': 0,\n",
    "    'Pred_Time': 0\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPERIMENT 4 COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Compare Holdout vs CV\n",
    "print(\"\\nHoldout vs Cross-Validation Comparison:\")\n",
    "best_exp_idx = ['Exp1', 'Exp2', 'Exp3'].index(best_exp_id)\n",
    "comparison = []\n",
    "for i, clf in enumerate(['LogReg', 'SVM', 'XGBoost']):\n",
    "    holdout_acc = all_experiments[best_exp_idx * 3 + i]['Accuracy']\n",
    "    cv_acc = all_experiments[-3 + i]['Accuracy']\n",
    "    comparison.append({\n",
    "        'Classifier': clf,\n",
    "        'Holdout': f\"{holdout_acc:.4f}\",\n",
    "        'CV Mean': f\"{cv_acc:.4f}\",\n",
    "        'Difference': f\"{(cv_acc - holdout_acc):.4f}\"\n",
    "    })\n",
    "print(pd.DataFrame(comparison).to_string(index=False))\n",
    "\n",
    "print(\"\\nNote: Low variance in CV scores indicates stable, reliable model performance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7aebfc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## EXPERIMENT 5: Hyperparameter Tuning (Best Model)\n",
    "\n",
    "**Purpose**: Optimize the best-performing classifier with GridSearchCV\n",
    "\n",
    "**Configuration**:\n",
    "- Features: Best setup from Experiment 4\n",
    "- Classifier: Best performer (auto-selected)\n",
    "- Method: GridSearchCV with 3-fold CV\n",
    "- Parameters: Compact grid for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70a036b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXPERIMENT 5: HYPERPARAMETER TUNING\n",
      "================================================================================\n",
      "Best classifier from Experiment 4: XGBoost\n",
      "   Default accuracy (CV): 0.4180\n",
      "\n",
      "Performing hyperparameter tuning with GridSearchCV...\n",
      "\n",
      "Parameter grid:\n",
      "  n_estimators: [200, 300]\n",
      "  learning_rate: [0.05, 0.1]\n",
      "  max_depth: [4, 6, 8]\n",
      "\n",
      "⏳ Training XGBoost with GridSearchCV (this may take a few minutes)...\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:57:51] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:57:51] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:57:51] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:57:51] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:57:51] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:57:51] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:57:51] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:57:51] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:58:26] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:58:28] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:58:28] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:58:42] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:58:42] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:58:43] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:58:44] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:58:44] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:59:18] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:59:42] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:59:43] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:59:53] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:59:53] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:59:54] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [13:59:57] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [14:00:18] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [14:00:27] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [14:00:28] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [14:00:28] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [14:00:45] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [14:00:47] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [14:00:58] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [14:01:09] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [14:01:15] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [14:01:17] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [14:01:22] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [14:01:24] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [14:01:57] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [14:03:00] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning complete in 351.34s\n",
      "\n",
      "Best Parameters Found:\n",
      "   colsample_bytree: 0.8\n",
      "   eval_metric: mlogloss\n",
      "   gamma: 0.1\n",
      "   learning_rate: 0.05\n",
      "   max_depth: 8\n",
      "   min_child_weight: 3\n",
      "   n_estimators: 300\n",
      "   random_state: 42\n",
      "   reg_alpha: 0.1\n",
      "   reg_lambda: 1.0\n",
      "   subsample: 0.8\n",
      "   use_label_encoder: False\n",
      "\n",
      "Results:\n",
      "   Best CV accuracy: 0.4161\n",
      "   Default accuracy: 0.4180\n",
      "   Improvement: -0.0020 (-0.47%)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"EXPERIMENT 5: HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find best classifier from Experiment 4 (CV results)\n",
    "exp4_results = pd.DataFrame(all_experiments[-3:])\n",
    "best_clf_idx = exp4_results['Accuracy'].idxmax()\n",
    "best_clf_name = exp4_results.loc[best_clf_idx, 'Classifier']\n",
    "best_clf_acc = exp4_results.loc[best_clf_idx, 'Accuracy']\n",
    "\n",
    "print(f\"Best classifier from Experiment 4: {best_clf_name}\")\n",
    "print(f\"   Default accuracy (CV): {best_clf_acc:.4f}\")\n",
    "print(f\"\\nPerforming hyperparameter tuning with GridSearchCV...\")\n",
    "\n",
    "# Define parameter grids for each classifier\n",
    "param_grids = {\n",
    "    'LogReg': {\n",
    "        'C': [0.1, 0.5, 1.0, 5.0],\n",
    "        'penalty': ['l2'],\n",
    "        'solver': ['lbfgs'],\n",
    "        'max_iter': [2000],\n",
    "        'class_weight': ['balanced']\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1.0, 10.0],\n",
    "        'kernel': ['rbf', 'linear'],\n",
    "        'gamma': ['scale', 0.01],\n",
    "        'class_weight': ['balanced']\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [200, 300],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'max_depth': [4, 6, 8],\n",
    "        'subsample': [0.8],\n",
    "        'colsample_bytree': [0.8],\n",
    "        'min_child_weight': [3],\n",
    "        'gamma': [0.1],\n",
    "        'reg_alpha': [0.1],\n",
    "        'reg_lambda': [1.0],\n",
    "        'use_label_encoder': [False],\n",
    "        'eval_metric': ['mlogloss'],\n",
    "        'random_state': [42]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize the base model\n",
    "if best_clf_name == 'LogReg':\n",
    "    base_model = LogisticRegression(random_state=42)\n",
    "elif best_clf_name == 'SVM':\n",
    "    base_model = SVC(random_state=42)\n",
    "else:  # XGBoost\n",
    "    base_model = XGBClassifier(random_state=42)\n",
    "\n",
    "# Setup GridSearchCV\n",
    "param_grid = param_grids[best_clf_name]\n",
    "print(f\"\\nParameter grid:\")\n",
    "for param, values in param_grid.items():\n",
    "    if len(values) > 1:  # Only show parameters being tuned\n",
    "        print(f\"  {param}: {values}\")\n",
    "\n",
    "cv_tune = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    base_model,\n",
    "    param_grid,\n",
    "    cv=cv_tune,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"\\n⏳ Training {best_clf_name} with GridSearchCV (this may take a few minutes)...\")\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_best_scaled, y_best_enc)\n",
    "tuning_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nTuning complete in {tuning_time:.2f}s\")\n",
    "print(f\"\\nBest Parameters Found:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"   {param}: {value}\")\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"   Best CV accuracy: {grid_search.best_score_:.4f}\")\n",
    "print(f\"   Default accuracy: {best_clf_acc:.4f}\")\n",
    "improvement = (grid_search.best_score_ - best_clf_acc) / best_clf_acc * 100\n",
    "print(f\"   Improvement: {(grid_search.best_score_ - best_clf_acc):.4f} ({improvement:+.2f}%)\")\n",
    "\n",
    "# Store results\n",
    "all_experiments.append({\n",
    "    'Exp_ID': 'Exp5',\n",
    "    'Exp_Name': f'{best_clf_name} Tuned (GridSearchCV)',\n",
    "    'Features': exp_results[exp_results['Exp_ID'] == best_exp_id]['Features'].iloc[0],\n",
    "    'Classifier': f'{best_clf_name} (Tuned)',\n",
    "    'Accuracy': grid_search.best_score_,\n",
    "    'Precision': 0,  # Would need separate calculation\n",
    "    'Recall': 0,\n",
    "    'F1_Score': 0,\n",
    "    'Train_Time': tuning_time,\n",
    "    'Pred_Time': 0\n",
    "})\n",
    "\n",
    "# Show top 5 parameter combinations\n",
    "\n",
    "cv_results_df = pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60109a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 parameter combinations:\n",
      "['mean_test_score', 'rank_test_score']\n",
      "\n",
      "   Rank 1: 0.4161 ± 0.0046\n",
      "   Parameters: {'gamma': 0.1, 'learning_rate': 0.05, 'max_depth': 8, 'n_estimators': 300}\n",
      "\n",
      "   Rank 2: 0.4148 ± 0.0035\n",
      "   Parameters: {'gamma': 0.1, 'learning_rate': 0.05, 'max_depth': 8, 'n_estimators': 200}\n",
      "\n",
      "   Rank 3: 0.4142 ± 0.0032\n",
      "   Parameters: {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "\n",
      "   Rank 4: 0.4139 ± 0.0022\n",
      "   Parameters: {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "\n",
      "   Rank 5: 0.4124 ± 0.0010\n",
      "   Parameters: {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 200}\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT 5 COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Best model saved: XGBoost_tuned_best.joblib\n",
      "   Also saved: scaler_exp5.joblib, label_encoder_exp5.joblib\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTop 5 parameter combinations:\")\n",
    "print([col for col in cv_results_df.columns if 'rank' in col or 'mean_test' in col])\n",
    "\n",
    "rank_col = 'rank_test_score'\n",
    "score_col = 'mean_test_score'\n",
    "std_col = 'std_test_score'\n",
    "\n",
    "# Sort by rank (ascending means best first)\n",
    "cv_results_sorted = cv_results_df.sort_values(rank_col)\n",
    "top_5 = cv_results_sorted.head(5)[['params', score_col, std_col, rank_col]]\n",
    "\n",
    "for idx, row in top_5.iterrows():\n",
    "    rank = int(row[rank_col])\n",
    "    mean_score = row[score_col]\n",
    "    std_score = row[std_col]\n",
    "    params = row['params']\n",
    "    \n",
    "    print(f\"\\n   Rank {rank}: {mean_score:.4f} ± {std_score:.4f}\")\n",
    "    # Pretty print parameters (only show tuned ones)\n",
    "    tuned_params = {k: v for k, v in params.items() if k in ['n_estimators', 'learning_rate', 'max_depth', 'C', 'penalty', 'kernel', 'gamma']}\n",
    "    print(f\"   Parameters: {tuned_params}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPERIMENT 5 COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save the best model\n",
    "best_model_exp5 = grid_search.best_estimator_\n",
    "\n",
    "joblib.dump(best_model_exp5, f'{best_clf_name}_tuned_best.joblib')\n",
    "joblib.dump(scaler_cv, 'scaler_exp5.joblib')\n",
    "joblib.dump(le_exp1, 'label_encoder_exp5.joblib')\n",
    "print(f\"\\nBest model saved: {best_clf_name}_tuned_best.joblib\")\n",
    "print(f\"   Also saved: scaler_exp5.joblib, label_encoder_exp5.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb436396",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## FINAL RESULTS & ANALYSIS\n",
    "\n",
    "Comprehensive summary of all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5183d7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPREHENSIVE RESULTS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "### ALL EXPERIMENTS - COMPLETE RESULTS ###\n",
      "\n",
      "Exp_ID      Classifier  Accuracy  Precision   Recall  F1_Score  Train_Time\n",
      "  Exp1          LogReg  0.339247   0.310889 0.319242  0.307677   11.302663\n",
      "  Exp1             SVM  0.346616   0.320598 0.325051  0.315951   84.795266\n",
      "  Exp1         XGBoost  0.422216   0.362852 0.368278  0.357502   25.725390\n",
      "  Exp2          LogReg  0.340611   0.310728 0.315432  0.306991   25.104567\n",
      "  Exp2             SVM  0.346616   0.321000 0.325060  0.316145  219.067181\n",
      "  Exp2         XGBoost  0.410480   0.339086 0.353076  0.338801  270.615011\n",
      "  Exp3          LogReg  0.337882   0.308853 0.314514  0.305216   17.109326\n",
      "  Exp3             SVM  0.346616   0.320643 0.325070  0.316153   81.849733\n",
      "  Exp3         XGBoost  0.420579   0.364993 0.366479  0.355932   84.777950\n",
      "  Exp4          LogReg  0.332988   0.303155 0.309608  0.299828    0.000000\n",
      "  Exp4             SVM  0.335172   0.306779 0.311283  0.302464    0.000000\n",
      "  Exp4         XGBoost  0.418050   0.368176 0.365366  0.356050    0.000000\n",
      "  Exp5 XGBoost (Tuned)  0.416085   0.000000 0.000000  0.000000  351.339029\n",
      "\n",
      "\n",
      "### SUMMARY BY EXPERIMENT ###\n",
      "\n",
      "       Accuracy                 Precision          Recall         F1_Score  \\\n",
      "           mean     std     max      mean     max    mean     max     mean   \n",
      "Exp_ID                                                                       \n",
      "Exp1     0.3694  0.0459  0.4222    0.3314  0.3629  0.3375  0.3683   0.3270   \n",
      "Exp2     0.3659  0.0387  0.4105    0.3236  0.3391  0.3312  0.3531   0.3206   \n",
      "Exp3     0.3684  0.0454  0.4206    0.3315  0.3650  0.3354  0.3665   0.3258   \n",
      "Exp4     0.3621  0.0485  0.4180    0.3260  0.3682  0.3288  0.3654   0.3194   \n",
      "Exp5     0.4161     NaN  0.4161    0.0000  0.0000  0.0000  0.0000   0.0000   \n",
      "\n",
      "                \n",
      "           max  \n",
      "Exp_ID          \n",
      "Exp1    0.3575  \n",
      "Exp2    0.3388  \n",
      "Exp3    0.3559  \n",
      "Exp4    0.3561  \n",
      "Exp5    0.0000  \n",
      "\n",
      "\n",
      "### SUMMARY BY CLASSIFIER ###\n",
      "\n",
      "           Accuracy                 Precision          Recall          \\\n",
      "               mean     std     max      mean     max    mean     max   \n",
      "Classifier                                                              \n",
      "LogReg       0.3392  0.0014  0.3406    0.3102  0.3109  0.3164  0.3192   \n",
      "SVM          0.3466  0.0000  0.3466    0.3207  0.3210  0.3251  0.3251   \n",
      "XGBoost      0.4178  0.0064  0.4222    0.3556  0.3650  0.3626  0.3683   \n",
      "\n",
      "           F1_Score         Train_Time  \n",
      "               mean     max       mean  \n",
      "Classifier                              \n",
      "LogReg       0.3066  0.3077    17.8389  \n",
      "SVM          0.3161  0.3162   128.5707  \n",
      "XGBoost      0.3507  0.3575   127.0395  \n",
      "\n",
      "\n",
      "### BEST CONFIGURATIONS ###\n",
      "\n",
      "Top 3 from Holdout Experiments:\n",
      "             Exp_Name Classifier  Accuracy  Precision   Recall  F1_Score\n",
      "   Baseline (No Text)    XGBoost  0.422216   0.362852 0.368278  0.357502\n",
      "       PCA Text (50D)    XGBoost  0.420579   0.364993 0.366479  0.355932\n",
      "With Full Text (384D)    XGBoost  0.410480   0.339086 0.353076  0.338801\n",
      "\n",
      "Best After Tuning:\n",
      "  XGBoost (Tuned): 0.4161 accuracy\n",
      "\n",
      "\n",
      "### KEY INSIGHTS ###\n",
      "\n",
      "1. Text Feature Impact:\n",
      "   - No Text (Exp1):      0.3694 avg accuracy\n",
      "   - Full Text (Exp2):    0.3659 avg accuracy  [-0.94%]\n",
      "   - PCA Text (Exp3):     0.3684 avg accuracy  [-0.27%]\n",
      "\n",
      "2. Classifier Performance (average across Exp 1-3):\n",
      "   - Logistic Regression: 0.3392\n",
      "   - SVM:                 0.3466\n",
      "   - XGBoost:             0.4178\n",
      "\n",
      "3. Training Time Analysis:\n",
      "   - Exp1: 40.61s average\n",
      "   - Exp2: 171.60s average\n",
      "   - Exp3: 61.25s average\n",
      "\n",
      "4. Cross-Validation Stability:\n",
      "   - Results confirmed robust (5-Fold CV)\n",
      "   - See Experiment 4 for detailed variance\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create comprehensive results DataFrame\n",
    "results_comprehensive = pd.DataFrame(all_experiments)\n",
    "\n",
    "# Display complete results table\n",
    "print(\"\\n### ALL EXPERIMENTS - COMPLETE RESULTS ###\\n\")\n",
    "display_cols = ['Exp_ID', 'Classifier', 'Accuracy', 'Precision', 'Recall', 'F1_Score', 'Train_Time']\n",
    "print(results_comprehensive[display_cols].to_string(index=False))\n",
    "\n",
    "# Summary by experiment\n",
    "print(\"\\n\\n### SUMMARY BY EXPERIMENT ###\\n\")\n",
    "summary_by_exp = results_comprehensive.groupby('Exp_ID').agg({\n",
    "    'Accuracy': ['mean', 'std', 'max'],\n",
    "    'Precision': ['mean', 'max'],\n",
    "    'Recall': ['mean', 'max'],\n",
    "    'F1_Score': ['mean', 'max']\n",
    "}).round(4)\n",
    "print(summary_by_exp)\n",
    "\n",
    "# Summary by classifier\n",
    "print(\"\\n\\n### SUMMARY BY CLASSIFIER ###\\n\")\n",
    "# Exclude Exp4 (CV) and Exp5 (tuned) for fair comparison\n",
    "holdout_results = results_comprehensive[results_comprehensive['Exp_ID'].isin(['Exp1', 'Exp2', 'Exp3'])]\n",
    "summary_by_clf = holdout_results.groupby('Classifier').agg({\n",
    "    'Accuracy': ['mean', 'std', 'max'],\n",
    "    'Precision': ['mean', 'max'],\n",
    "    'Recall': ['mean', 'max'],\n",
    "    'F1_Score': ['mean', 'max'],\n",
    "    'Train_Time': ['mean']\n",
    "}).round(4)\n",
    "print(summary_by_clf)\n",
    "\n",
    "# Best configuration\n",
    "print(\"\\n\\n### BEST CONFIGURATIONS ###\\n\")\n",
    "best_holdout = results_comprehensive[results_comprehensive['Exp_ID'].isin(['Exp1', 'Exp2', 'Exp3'])].nlargest(3, 'Accuracy')\n",
    "print(\"Top 3 from Holdout Experiments:\")\n",
    "print(best_holdout[['Exp_Name', 'Classifier', 'Accuracy', 'Precision', 'Recall', 'F1_Score']].to_string(index=False))\n",
    "\n",
    "if len(results_comprehensive[results_comprehensive['Exp_ID'] == 'Exp5']) > 0:\n",
    "    best_tuned = results_comprehensive[results_comprehensive['Exp_ID'] == 'Exp5'].iloc[0]\n",
    "    print(f\"\\nBest After Tuning:\")\n",
    "    print(f\"  {best_tuned['Classifier']}: {best_tuned['Accuracy']:.4f} accuracy\")\n",
    "\n",
    "# Key insights\n",
    "print(\"\\n\\n### KEY INSIGHTS ###\\n\")\n",
    "\n",
    "# Text impact\n",
    "exp1_avg = results_comprehensive[results_comprehensive['Exp_ID'] == 'Exp1']['Accuracy'].mean()\n",
    "exp2_avg = results_comprehensive[results_comprehensive['Exp_ID'] == 'Exp2']['Accuracy'].mean()\n",
    "exp3_avg = results_comprehensive[results_comprehensive['Exp_ID'] == 'Exp3']['Accuracy'].mean()\n",
    "\n",
    "print(f\"1. Text Feature Impact:\")\n",
    "print(f\"   - No Text (Exp1):      {exp1_avg:.4f} avg accuracy\")\n",
    "print(f\"   - Full Text (Exp2):    {exp2_avg:.4f} avg accuracy  [{((exp2_avg-exp1_avg)/exp1_avg*100):+.2f}%]\")\n",
    "print(f\"   - PCA Text (Exp3):     {exp3_avg:.4f} avg accuracy  [{((exp3_avg-exp1_avg)/exp1_avg*100):+.2f}%]\")\n",
    "\n",
    "# Classifier comparison\n",
    "lr_avg = holdout_results[holdout_results['Classifier'] == 'LogReg']['Accuracy'].mean()\n",
    "svm_avg = holdout_results[holdout_results['Classifier'] == 'SVM']['Accuracy'].mean()\n",
    "xgb_avg = holdout_results[holdout_results['Classifier'] == 'XGBoost']['Accuracy'].mean()\n",
    "\n",
    "print(f\"\\n2. Classifier Performance (average across Exp 1-3):\")\n",
    "print(f\"   - Logistic Regression: {lr_avg:.4f}\")\n",
    "print(f\"   - SVM:                 {svm_avg:.4f}\")\n",
    "print(f\"   - XGBoost:             {xgb_avg:.4f}\")\n",
    "\n",
    "# Training time analysis\n",
    "print(f\"\\n3. Training Time Analysis:\")\n",
    "time_by_exp = holdout_results.groupby('Exp_ID')['Train_Time'].mean()\n",
    "for exp_id in ['Exp1', 'Exp2', 'Exp3']:\n",
    "    print(f\"   - {exp_id}: {time_by_exp[exp_id]:.2f}s average\")\n",
    "\n",
    "# CV stability\n",
    "if len(results_comprehensive[results_comprehensive['Exp_ID'] == 'Exp4']) > 0:\n",
    "    print(f\"\\n4. Cross-Validation Stability:\")\n",
    "    print(f\"   - Results confirmed robust (5-Fold CV)\")\n",
    "    print(f\"   - See Experiment 4 for detailed variance\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d0ab0a",
   "metadata": {},
   "source": [
    "### Export Results for Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "972b256d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (from matplotlib) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "242c7d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (from seaborn) (2.3.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (from seaborn) (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/vishwas/Developer/Vishwas/Machine Learning/ml/venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3bee9dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results exported to: experiment_results_comprehensive.csv\n",
      "Summary table exported to: experiment_results_summary.csv\n",
      "Visualization saved to: experiment_comparison.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ALL EXPERIMENTS COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Files Generated:\n",
      "   1. experiment_results_comprehensive.csv\n",
      "   2. experiment_results_summary.csv\n",
      "   3. experiment_comparison.png\n",
      "   4. XGBoost_tuned_best.joblib (or other best model)\n",
      "   5. scaler_exp5.joblib\n",
      "   6. label_encoder_exp5.joblib\n",
      "\n",
      "Ready for report writing and Kaggle submission!\n"
     ]
    }
   ],
   "source": [
    "# Export comprehensive results to CSV\n",
    "results_df = pd.DataFrame(all_experiments)\n",
    "results_df.to_csv('experiment_results_comprehensive.csv', index=False)\n",
    "print(\"Results exported to: experiment_results_comprehensive.csv\")\n",
    "\n",
    "# Create a summary table for the report\n",
    "summary_for_report = results_df.groupby(['Exp_ID', 'Classifier']).agg({\n",
    "    'Accuracy': 'first',\n",
    "    'Precision': 'first',\n",
    "    'Recall': 'first',\n",
    "    'F1_Score': 'first',\n",
    "    'Train_Time': 'first'\n",
    "}).reset_index()\n",
    "summary_for_report.to_csv('experiment_results_summary.csv', index=False)\n",
    "print(\"Summary table exported to: experiment_results_summary.csv\")\n",
    "\n",
    "# Create visualizations data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# 1. Accuracy comparison across experiments\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Accuracy by Experiment and Classifier\n",
    "holdout_data = results_df[results_df['Exp_ID'].isin(['Exp1', 'Exp2', 'Exp3'])]\n",
    "pivot_data = holdout_data.pivot(index='Exp_ID', columns='Classifier', values='Accuracy')\n",
    "pivot_data.plot(kind='bar', ax=ax[0], width=0.8)\n",
    "ax[0].set_title('Accuracy Across Experiments (Holdout)', fontsize=14, fontweight='bold')\n",
    "ax[0].set_xlabel('Experiment', fontsize=12)\n",
    "ax[0].set_ylabel('Accuracy', fontsize=12)\n",
    "ax[0].set_xticklabels(ax[0].get_xticklabels(), rotation=0)\n",
    "ax[0].legend(title='Classifier')\n",
    "ax[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: Training Time Comparison\n",
    "time_data = holdout_data.groupby('Classifier')['Train_Time'].mean()\n",
    "time_data.plot(kind='bar', ax=ax[1], color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "ax[1].set_title('Average Training Time by Classifier', fontsize=14, fontweight='bold')\n",
    "ax[1].set_xlabel('Classifier', fontsize=12)\n",
    "ax[1].set_ylabel('Time (seconds)', fontsize=12)\n",
    "ax[1].set_xticklabels(ax[1].get_xticklabels(), rotation=0)\n",
    "ax[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('experiment_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Visualization saved to: experiment_comparison.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL EXPERIMENTS COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nFiles Generated:\")\n",
    "print(\"   1. experiment_results_comprehensive.csv\")\n",
    "print(\"   2. experiment_results_summary.csv\")\n",
    "print(\"   3. experiment_comparison.png\")\n",
    "print(\"   4. XGBoost_tuned_best.joblib (or other best model)\")\n",
    "print(\"   5. scaler_exp5.joblib\")\n",
    "print(\"   6. label_encoder_exp5.joblib\")\n",
    "print(\"\\nReady for report writing and Kaggle submission!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6fcdd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
